# Phase 4-8: ê³ ê¸‰ ì£¼ì œ ë° ìš´ì˜

> ìŠ¤ì¼€ì¼ë§, ë°°í¬, ëª¨ë‹ˆí„°ë§, ë³´ì•ˆ

## ëª©ì°¨

- [Phase 4: ë¦¬ì†ŒìŠ¤ ê²©ë¦¬ ë° í• ë‹¹ëŸ‰](#phase-4-ë¦¬ì†ŒìŠ¤-ê²©ë¦¬-ë°-í• ë‹¹ëŸ‰)
- [Phase 5: ìŠ¤ì¼€ì¼ë§ ì „ëµ](#phase-5-ìŠ¤ì¼€ì¼ë§-ì „ëµ)
- [Phase 6: ë°°í¬ ë° CI/CD](#phase-6-ë°°í¬-ë°-cicd)
- [Phase 7: ëª¨ë‹ˆí„°ë§ ë° ìš´ì˜](#phase-7-ëª¨ë‹ˆí„°ë§-ë°-ìš´ì˜)
- [Phase 8: ë³´ì•ˆ ê°•í™”](#phase-8-ë³´ì•ˆ-ê°•í™”)

---

## Phase 4: ë¦¬ì†ŒìŠ¤ ê²©ë¦¬ ë° í• ë‹¹ëŸ‰

### 4.1 ì‘ì—… ìš°ì„ ìˆœìœ„ ì‹œìŠ¤í…œ

**ëª©í‘œ**: Pro ì‚¬ìš©ìëŠ” Free ì‚¬ìš©ìë³´ë‹¤ ë¹ ë¥´ê²Œ ì²˜ë¦¬

```python
# invokeai/app/services/queue/priority_queue.py
from enum import IntEnum


class QueuePriority(IntEnum):
    """ìš°ì„ ìˆœìœ„ ì •ì˜ (ë†’ì„ìˆ˜ë¡ ë¨¼ì € ì²˜ë¦¬)"""
    FREE = 0
    PRO = 10
    ENTERPRISE = 100


def get_priority_for_user(subscription_tier: str) -> int:
    """ì‚¬ìš©ì êµ¬ë… í”Œëœì— ë”°ë¥¸ ìš°ì„ ìˆœìœ„"""
    priority_map = {
        "free": QueuePriority.FREE,
        "pro": QueuePriority.PRO,
        "enterprise": QueuePriority.ENTERPRISE,
    }
    return priority_map.get(subscription_tier, QueuePriority.FREE)
```

**Celeryì—ì„œ ìš°ì„ ìˆœìœ„ ì ìš©:**

```python
# invokeai/app/celery_app.py
from celery import Celery


app = Celery("invokeai")

app.conf.update(
    broker_url="redis://redis:6379/0",
    result_backend="redis://redis:6379/1",

    # ìš°ì„ ìˆœìœ„ ì„¤ì •
    task_queue_max_priority=100,
    task_default_priority=0,

    # ë¼ìš°íŒ…
    task_routes={
        "invokeai.tasks.generate_image": {
            "queue": "gpu-generation",
        },
    },
)


@app.task(bind=True, max_retries=3)
def generate_image(self, task_params: dict):
    """ì´ë¯¸ì§€ ìƒì„± ì‘ì—…"""

    # ìš°ì„ ìˆœìœ„ëŠ” ì‘ì—… íì— ì¶”ê°€í•  ë•Œ ì„¤ì •ë¨
    # apply_async(priority=10)

    user_id = task_params["user_id"]
    workflow = task_params["workflow"]

    # ... ìƒì„± ë¡œì§
```

**íì— ì‘ì—… ì¶”ê°€ ì‹œ ìš°ì„ ìˆœìœ„ ì„¤ì •:**

```python
# invokeai/app/api/routers/session_queue.py
@router.post("/enqueue_batch")
async def enqueue_batch(
    queue_batch: EnqueueBatchParams,
    user: TokenData = Depends(get_current_user),
):
    # ì‚¬ìš©ì êµ¬ë… í”Œëœì— ë”°ë¥¸ ìš°ì„ ìˆœìœ„
    priority = get_priority_for_user(user.subscription_tier)

    # Celery ì‘ì—… íì— ì¶”ê°€
    task = generate_image.apply_async(
        args=[{
            "user_id": user.user_id,
            "workflow": queue_batch.graph,
        }],
        priority=priority,  # âœ… ìš°ì„ ìˆœìœ„ ì ìš©
        queue="gpu-generation",
    )

    return {"task_id": task.id, "priority": priority}
```

### 4.2 ë™ì‹œ ì‘ì—… ì œí•œ

```python
# invokeai/app/services/concurrency/limiter.py
import redis
from typing import Optional


class ConcurrencyLimiter:
    """ë™ì‹œ ì‘ì—… ìˆ˜ ì œí•œ"""

    def __init__(self, redis_client: redis.Redis):
        self._redis = redis_client

    async def acquire(
        self,
        user_id: str,
        subscription_tier: str,
    ) -> bool:
        """
        ì‘ì—… ìŠ¬ë¡¯ íšë“ ì‹œë„

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """

        # í”Œëœë³„ ë™ì‹œ ì‘ì—… í•œë„
        limits = {
            "free": 1,        # Free: 1ê°œì”©ë§Œ
            "pro": 3,         # Pro: 3ê°œ ë™ì‹œ
            "enterprise": 10,  # Enterprise: 10ê°œ ë™ì‹œ
        }

        max_concurrent = limits.get(subscription_tier, 1)

        # Redisì—ì„œ í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ìˆ˜ ì¡°íšŒ
        key = f"concurrent:{user_id}"
        current = int(self._redis.get(key) or 0)

        if current >= max_concurrent:
            return False  # í•œë„ ì´ˆê³¼

        # ì‘ì—… ì¹´ìš´íŠ¸ ì¦ê°€ (24ì‹œê°„ TTL)
        self._redis.incr(key)
        self._redis.expire(key, 86400)

        return True

    async def release(self, user_id: str):
        """ì‘ì—… ìŠ¬ë¡¯ í•´ì œ"""
        key = f"concurrent:{user_id}"
        self._redis.decr(key)
```

**ì‚¬ìš© ì˜ˆì‹œ:**

```python
@router.post("/enqueue_batch")
async def enqueue_batch(
    queue_batch: EnqueueBatchParams,
    user: TokenData = Depends(get_current_user),
    limiter: ConcurrencyLimiter = Depends(ApiDependencies.concurrency_limiter),
):
    # ë™ì‹œ ì‘ì—… í•œë„ ì²´í¬
    if not await limiter.acquire(user.user_id, user.subscription_tier):
        raise HTTPException(
            status_code=status.HTTP_429_TOO_MANY_REQUESTS,
            detail="Too many concurrent requests. Please wait for current tasks to complete.",
        )

    # ì‘ì—… íì— ì¶”ê°€
    task = generate_image.apply_async(...)

    return {"task_id": task.id}
```

---

## Phase 5: ìŠ¤ì¼€ì¼ë§ ì „ëµ

### 5.1 ìˆ˜í‰ ìŠ¤ì¼€ì¼ë§ (Horizontal Scaling)

**ECS Service Auto Scaling:**

```hcl
# terraform/ecs_autoscaling.tf

# API ì„œë²„ Auto Scaling
resource "aws_appautoscaling_target" "ecs_service" {
  max_capacity       = 10
  min_capacity       = 2
  resource_id        = "service/${aws_ecs_cluster.main.name}/${aws_ecs_service.api.name}"
  scalable_dimension = "ecs:service:DesiredCount"
  service_namespace  = "ecs"
}

# CPU ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
resource "aws_appautoscaling_policy" "ecs_cpu" {
  name               = "cpu-autoscaling"
  policy_type        = "TargetTrackingScaling"
  resource_id        = aws_appautoscaling_target.ecs_service.resource_id
  scalable_dimension = aws_appautoscaling_target.ecs_service.scalable_dimension
  service_namespace  = aws_appautoscaling_target.ecs_service.service_namespace

  target_tracking_scaling_policy_configuration {
    target_value = 70.0  # CPU 70% ìœ ì§€

    predefined_metric_specification {
      predefined_metric_type = "ECSServiceAverageCPUUtilization"
    }

    scale_in_cooldown  = 300  # 5ë¶„
    scale_out_cooldown = 60   # 1ë¶„
  }
}

# ìš”ì²­ ìˆ˜ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
resource "aws_appautoscaling_policy" "ecs_requests" {
  name               = "requests-autoscaling"
  policy_type        = "TargetTrackingScaling"
  resource_id        = aws_appautoscaling_target.ecs_service.resource_id
  scalable_dimension = aws_appautoscaling_target.ecs_service.scalable_dimension
  service_namespace  = aws_appautoscaling_target.ecs_service.service_namespace

  target_tracking_scaling_policy_configuration {
    target_value = 1000.0  # ì»¨í…Œì´ë„ˆë‹¹ 1000 req/min

    predefined_metric_specification {
      predefined_metric_type = "ALBRequestCountPerTarget"
      resource_label         = "${aws_lb.main.arn_suffix}/${aws_lb_target_group.api.arn_suffix}"
    }
  }
}
```

**GPU ì›Œì»¤ Auto Scaling (í ê¹Šì´ ê¸°ë°˜):**

```hcl
# terraform/gpu_autoscaling.tf

# CloudWatch ì•ŒëŒ - í ê¹Šì´ ë†’ìŒ
resource "aws_cloudwatch_metric_alarm" "queue_depth_high" {
  alarm_name          = "gpu-queue-depth-high"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "ApproximateNumberOfMessagesVisible"
  namespace           = "AWS/SQS"
  period              = "60"
  statistic           = "Average"
  threshold           = "10"  # íì— 10ê°œ ì´ìƒ
  alarm_description   = "Scale up GPU workers"

  dimensions = {
    QueueName = "invokeai-gpu-queue"
  }

  alarm_actions = [aws_autoscaling_policy.gpu_scale_up.arn]
}

# CloudWatch ì•ŒëŒ - í ê¹Šì´ ë‚®ìŒ
resource "aws_cloudwatch_metric_alarm" "queue_depth_low" {
  alarm_name          = "gpu-queue-depth-low"
  comparison_operator = "LessThanThreshold"
  evaluation_periods  = "5"
  metric_name         = "ApproximateNumberOfMessagesVisible"
  namespace           = "AWS/SQS"
  period              = "60"
  statistic           = "Average"
  threshold           = "2"  # íì— 2ê°œ ë¯¸ë§Œ
  alarm_description   = "Scale down GPU workers"

  dimensions = {
    QueueName = "invokeai-gpu-queue"
  }

  alarm_actions = [aws_autoscaling_policy.gpu_scale_down.arn]
}

# Scale Up ì •ì±…
resource "aws_autoscaling_policy" "gpu_scale_up" {
  name                   = "gpu-scale-up"
  scaling_adjustment     = 2  # 2ëŒ€ì”© ì¦ê°€
  adjustment_type        = "ChangeInCapacity"
  cooldown              = 300  # 5ë¶„ ëŒ€ê¸°
  autoscaling_group_name = aws_autoscaling_group.gpu_workers.name
}

# Scale Down ì •ì±…
resource "aws_autoscaling_policy" "gpu_scale_down" {
  name                   = "gpu-scale-down"
  scaling_adjustment     = -1  # 1ëŒ€ì”© ê°ì†Œ
  adjustment_type        = "ChangeInCapacity"
  cooldown              = 600  # 10ë¶„ ëŒ€ê¸°
  autoscaling_group_name = aws_autoscaling_group.gpu_workers.name
}
```

### 5.2 ìºì‹± ì „ëµ

**1) ëª¨ë¸ ë©”íƒ€ë°ì´í„° ìºì‹±:**

```python
# invokeai/app/services/models/model_cache.py
import redis
import json
from typing import Optional


class ModelMetadataCache:
    """ëª¨ë¸ ë©”íƒ€ë°ì´í„° Redis ìºì‹±"""

    def __init__(self, redis_client: redis.Redis):
        self._redis = redis_client
        self._ttl = 3600  # 1ì‹œê°„

    def get(self, model_key: str) -> Optional[dict]:
        """ìºì‹œì—ì„œ ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
        cache_key = f"model:metadata:{model_key}"
        data = self._redis.get(cache_key)

        if data:
            return json.loads(data)
        return None

    def set(self, model_key: str, metadata: dict):
        """ìºì‹œì— ëª¨ë¸ ì •ë³´ ì €ì¥"""
        cache_key = f"model:metadata:{model_key}"
        self._redis.setex(
            cache_key,
            self._ttl,
            json.dumps(metadata),
        )

    def invalidate(self, model_key: str):
        """ìºì‹œ ë¬´íš¨í™”"""
        cache_key = f"model:metadata:{model_key}"
        self._redis.delete(cache_key)
```

**2) API ì‘ë‹µ ìºì‹±:**

```python
# invokeai/app/api/routers/models.py
from functools import lru_cache


@router.get("/models")
@cache(expire=300)  # 5ë¶„ ìºì‹œ
async def list_models(
    type: Optional[str] = None,
    base: Optional[str] = None,
):
    """ëª¨ë¸ ëª©ë¡ ì¡°íšŒ (ìºì‹œë¨)"""

    # ... ë¡œì§
```

**3) CloudFront CDN:**

```hcl
# terraform/cloudfront.tf

# CloudFront Distribution
resource "aws_cloudfront_distribution" "main" {
  enabled = true

  # Origin - S3 (ì´ë¯¸ì§€)
  origin {
    domain_name = aws_s3_bucket.images.bucket_regional_domain_name
    origin_id   = "S3-images"

    s3_origin_config {
      origin_access_identity = aws_cloudfront_origin_access_identity.main.cloudfront_access_identity_path
    }
  }

  # Origin - ALB (API)
  origin {
    domain_name = aws_lb.main.dns_name
    origin_id   = "ALB-api"

    custom_origin_config {
      http_port              = 80
      https_port             = 443
      origin_protocol_policy = "https-only"
      origin_ssl_protocols   = ["TLSv1.2"]
    }
  }

  # ìºì‹œ ë™ì‘ - ì´ë¯¸ì§€
  ordered_cache_behavior {
    path_pattern     = "/images/*"
    target_origin_id = "S3-images"

    allowed_methods = ["GET", "HEAD"]
    cached_methods  = ["GET", "HEAD"]

    forwarded_values {
      query_string = false
      cookies {
        forward = "none"
      }
    }

    min_ttl     = 0
    default_ttl = 86400   # 1ì¼
    max_ttl     = 31536000 # 1ë…„
    compress    = true

    viewer_protocol_policy = "redirect-to-https"
  }

  # ìºì‹œ ë™ì‘ - API (ìºì‹œ ì•ˆ í•¨)
  default_cache_behavior {
    target_origin_id = "ALB-api"

    allowed_methods = ["DELETE", "GET", "HEAD", "OPTIONS", "PATCH", "POST", "PUT"]
    cached_methods  = ["GET", "HEAD"]

    forwarded_values {
      query_string = true
      headers      = ["*"]
      cookies {
        forward = "all"
      }
    }

    min_ttl     = 0
    default_ttl = 0
    max_ttl     = 0

    viewer_protocol_policy = "redirect-to-https"
  }

  # SSL ì¸ì¦ì„œ
  viewer_certificate {
    acm_certificate_arn = aws_acm_certificate.main.arn
    ssl_support_method  = "sni-only"
  }

  restrictions {
    geo_restriction {
      restriction_type = "none"
    }
  }
}
```

---

## Phase 6: ë°°í¬ ë° CI/CD

### 6.1 GitHub Actions CI/CD íŒŒì´í”„ë¼ì¸

```yaml
# .github/workflows/deploy-prod.yml
name: Deploy to Production

on:
  push:
    branches: [main]

env:
  AWS_REGION: us-east-1
  ECR_REGISTRY: ${{ secrets.ECR_REGISTRY }}
  ECS_CLUSTER: invokeai-cluster
  ECS_SERVICE: invokeai-api

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov

      - name: Run tests
        run: |
          pytest tests/ --cov=invokeai --cov-report=xml

      - name: Upload coverage
        uses: codecov/codecov-action@v3

  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build, tag, and push image to Amazon ECR
        id: build-image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/invokeai-api:$IMAGE_TAG .
          docker push $ECR_REGISTRY/invokeai-api:$IMAGE_TAG
          docker tag $ECR_REGISTRY/invokeai-api:$IMAGE_TAG $ECR_REGISTRY/invokeai-api:latest
          docker push $ECR_REGISTRY/invokeai-api:latest
          echo "image=$ECR_REGISTRY/invokeai-api:$IMAGE_TAG" >> $GITHUB_OUTPUT

      - name: Fill in the new image ID in the Amazon ECS task definition
        id: task-def
        uses: aws-actions/amazon-ecs-render-task-definition@v1
        with:
          task-definition: task-definition.json
          container-name: api
          image: ${{ steps.build-image.outputs.image }}

      - name: Deploy Amazon ECS task definition
        uses: aws-actions/amazon-ecs-deploy-task-definition@v1
        with:
          task-definition: ${{ steps.task-def.outputs.task-definition }}
          service: ${{ env.ECS_SERVICE }}
          cluster: ${{ env.ECS_CLUSTER }}
          wait-for-service-stability: true

  migrate-database:
    needs: build-and-push
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Run database migrations
        run: |
          # Bastion í˜¸ìŠ¤íŠ¸ë¥¼ í†µí•´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
          # ë˜ëŠ” ECS Taskë¡œ ì‹¤í–‰
          aws ecs run-task \
            --cluster ${{ env.ECS_CLUSTER }} \
            --task-definition invokeai-migrate \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={subnets=[subnet-xxx],securityGroups=[sg-xxx]}"
```

### 6.2 Blue-Green ë°°í¬

```yaml
# .github/workflows/blue-green-deploy.yml
deploy:
  runs-on: ubuntu-latest
  steps:
    # ... (ë¹Œë“œ ë‹¨ê³„)

    - name: Create new target group (Green)
      run: |
        aws elbv2 create-target-group \
          --name invokeai-api-green \
          --protocol HTTP \
          --port 9090 \
          --vpc-id $VPC_ID

    - name: Deploy to Green environment
      run: |
        aws ecs update-service \
          --cluster invokeai-cluster \
          --service invokeai-api-green \
          --task-definition invokeai-api:${{ github.sha }}

    - name: Wait for Green environment to be healthy
      run: |
        aws ecs wait services-stable \
          --cluster invokeai-cluster \
          --services invokeai-api-green

    - name: Run smoke tests
      run: |
        ./scripts/smoke-test.sh https://green.api.yourdomain.com

    - name: Switch traffic to Green
      run: |
        # ALB ë¦¬ìŠ¤ë„ˆ ê·œì¹™ ìˆ˜ì •
        aws elbv2 modify-listener \
          --listener-arn $LISTENER_ARN \
          --default-actions Type=forward,TargetGroupArn=$GREEN_TG_ARN

    - name: Monitor for 10 minutes
      run: sleep 600

    - name: Rollback if errors detected
      if: failure()
      run: |
        aws elbv2 modify-listener \
          --listener-arn $LISTENER_ARN \
          --default-actions Type=forward,TargetGroupArn=$BLUE_TG_ARN
```

### 6.3 ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜

```python
# alembic/versions/002_add_feature_x.py
"""Add feature X

Revision ID: 002
Revises: 001
"""
from alembic import op
import sqlalchemy as sa


def upgrade():
    # ìƒˆ ì»¬ëŸ¼ ì¶”ê°€ (NULL í—ˆìš©)
    op.add_column('users', sa.Column('new_feature', sa.String(255), nullable=True))

    # ê¸°ë³¸ê°’ ì„¤ì •
    op.execute("UPDATE users SET new_feature = 'default_value'")

    # NOT NULL ì œì•½ ì¶”ê°€
    op.alter_column('users', 'new_feature', nullable=False)

    # ì¸ë±ìŠ¤ ì¶”ê°€
    op.create_index('idx_users_new_feature', 'users', ['new_feature'])


def downgrade():
    # ë¡¤ë°± ë¡œì§
    op.drop_index('idx_users_new_feature', table_name='users')
    op.drop_column('users', 'new_feature')
```

**ë°°í¬ ìŠ¤í¬ë¦½íŠ¸:**

```bash
#!/bin/bash
# scripts/deploy.sh

set -e

# 1. ë°±ì—…
echo "Creating database backup..."
aws rds create-db-snapshot \
  --db-instance-identifier invokeai-db \
  --db-snapshot-identifier invokeai-$(date +%Y%m%d-%H%M%S)

# 2. ë§ˆì´ê·¸ë ˆì´ì…˜
echo "Running database migrations..."
docker run --rm \
  -e DATABASE_URL=$DATABASE_URL \
  invokeai-api:latest \
  alembic upgrade head

# 3. ë°°í¬
echo "Deploying new version..."
aws ecs update-service \
  --cluster invokeai-cluster \
  --service invokeai-api \
  --force-new-deployment

echo "Deployment complete!"
```

---

## Phase 7: ëª¨ë‹ˆí„°ë§ ë° ìš´ì˜

### 7.1 CloudWatch ë©”íŠ¸ë¦­ ë° ì•ŒëŒ

```hcl
# terraform/monitoring.tf

# CloudWatch Dashboard
resource "aws_cloudwatch_dashboard" "main" {
  dashboard_name = "InvokeAI-Production"

  dashboard_body = jsonencode({
    widgets = [
      # API ì‘ë‹µ ì‹œê°„
      {
        type = "metric"
        properties = {
          metrics = [
            ["AWS/ApplicationELB", "TargetResponseTime", {stat = "Average"}]
          ]
          period = 300
          stat   = "Average"
          region = "us-east-1"
          title  = "API Response Time"
        }
      },

      # ì—ëŸ¬ìœ¨
      {
        type = "metric"
        properties = {
          metrics = [
            ["AWS/ApplicationELB", "HTTPCode_Target_5XX_Count", {stat = "Sum"}]
          ]
          period = 300
          stat   = "Sum"
          region = "us-east-1"
          title  = "5XX Errors"
        }
      },

      # GPU ì‚¬ìš©ë¥ 
      {
        type = "metric"
        properties = {
          metrics = [
            ["CWAgent", "gpu_utilization", {stat = "Average"}]
          ]
          period = 60
          stat   = "Average"
          region = "us-east-1"
          title  = "GPU Utilization"
        }
      },

      # í ê¹Šì´
      {
        type = "metric"
        properties = {
          metrics = [
            ["AWS/SQS", "ApproximateNumberOfMessagesVisible", {stat = "Average"}]
          ]
          period = 60
          stat   = "Average"
          region = "us-east-1"
          title  = "Queue Depth"
        }
      },
    ]
  })
}

# ì•ŒëŒ - API ì‘ë‹µ ì‹œê°„ ë†’ìŒ
resource "aws_cloudwatch_metric_alarm" "api_latency_high" {
  alarm_name          = "api-latency-high"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "TargetResponseTime"
  namespace           = "AWS/ApplicationELB"
  period              = "300"
  statistic           = "Average"
  threshold           = "1.0"  # 1ì´ˆ
  alarm_description   = "API response time is too high"

  alarm_actions = [aws_sns_topic.alerts.arn]
}

# ì•ŒëŒ - ì—ëŸ¬ìœ¨ ë†’ìŒ
resource "aws_cloudwatch_metric_alarm" "error_rate_high" {
  alarm_name          = "error-rate-high"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "1"
  metric_name         = "HTTPCode_Target_5XX_Count"
  namespace           = "AWS/ApplicationELB"
  period              = "300"
  statistic           = "Sum"
  threshold           = "10"  # 5ë¶„ì— 10ê°œ ì´ìƒ
  alarm_description   = "Too many 5XX errors"

  alarm_actions = [aws_sns_topic.alerts.arn]
}

# SNS Topic (ì•Œë¦¼)
resource "aws_sns_topic" "alerts" {
  name = "invokeai-alerts"
}

resource "aws_sns_topic_subscription" "alerts_email" {
  topic_arn = aws_sns_topic.alerts.arn
  protocol  = "email"
  endpoint  = "alerts@yourdomain.com"
}

# Slack í†µí•© (ì„ íƒ)
resource "aws_sns_topic_subscription" "alerts_slack" {
  topic_arn = aws_sns_topic.alerts.arn
  protocol  = "lambda"
  endpoint  = aws_lambda_function.slack_notifier.arn
}
```

### 7.2 ë¡œê¹… (CloudWatch Logs)

```python
# invokeai/app/util/logger.py
import logging
import watchtower  # CloudWatch Logs handler


def setup_logging(environment: str):
    """ë¡œê¹… ì„¤ì •"""

    logger = logging.getLogger("invokeai")
    logger.setLevel(logging.INFO)

    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(
        logging.Formatter(
            "[%(asctime)s] %(levelname)s [%(name)s:%(lineno)s] %(message)s"
        )
    )
    logger.addHandler(console_handler)

    # CloudWatch Logs í•¸ë“¤ëŸ¬ (í”„ë¡œë•ì…˜ë§Œ)
    if environment == "production":
        cloudwatch_handler = watchtower.CloudWatchLogHandler(
            log_group="/aws/ecs/invokeai",
            stream_name="api-server",
        )
        logger.addHandler(cloudwatch_handler)

    return logger
```

**êµ¬ì¡°í™”ëœ ë¡œê¹…:**

```python
import structlog


logger = structlog.get_logger()

logger.info(
    "image_generated",
    user_id=user_id,
    image_name=image_name,
    model="sdxl",
    resolution="1024x1024",
    generation_time_sec=15.2,
)
```

### 7.3 ì—ëŸ¬ ì¶”ì  (Sentry)

```python
# invokeai/app/run_app.py
import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration


if app_config.environment == "production":
    sentry_sdk.init(
        dsn="https://xxx@sentry.io/xxx",
        environment=app_config.environment,

        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        traces_sample_rate=0.1,  # 10% ìƒ˜í”Œë§

        # ë¦´ë¦¬ìŠ¤ ì¶”ì 
        release=f"invokeai@{app_config.version}",

        # í†µí•©
        integrations=[FastApiIntegration()],

        # í•„í„°ë§
        before_send=before_send_handler,
    )


def before_send_handler(event, hint):
    """ë¯¼ê°í•œ ì •ë³´ í•„í„°ë§"""

    # Authorization í—¤ë” ì œê±°
    if "request" in event:
        if "headers" in event["request"]:
            event["request"]["headers"].pop("Authorization", None)

    return event
```

**ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­:**

```python
from sentry_sdk import capture_message, set_tag, set_context


# íƒœê·¸ ì„¤ì •
set_tag("subscription_tier", user.subscription_tier)
set_tag("gpu_instance_type", "g5.xlarge")

# ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
set_context("generation_params", {
    "model": "sdxl",
    "steps": 30,
    "resolution": "1024x1024",
})

# ì´ë²¤íŠ¸ ìº¡ì²˜
capture_message("Generation completed", level="info")
```

---

## Phase 8: ë³´ì•ˆ ê°•í™”

### 8.1 WAF (Web Application Firewall)

```hcl
# terraform/waf.tf

# WAF Web ACL
resource "aws_wafv2_web_acl" "main" {
  name  = "invokeai-waf"
  scope = "REGIONAL"

  default_action {
    allow {}
  }

  # Rate Limiting (DDoS ë°©ì–´)
  rule {
    name     = "rate-limit"
    priority = 1

    statement {
      rate_based_statement {
        limit              = 2000  # IPë‹¹ 5ë¶„ì— 2000 req
        aggregate_key_type = "IP"
      }
    }

    action {
      block {}
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = "rate-limit"
      sampled_requests_enabled   = true
    }
  }

  # SQL Injection ì°¨ë‹¨
  rule {
    name     = "sql-injection"
    priority = 2

    statement {
      managed_rule_group_statement {
        vendor_name = "AWS"
        name        = "AWSManagedRulesSQLiRuleSet"
      }
    }

    override_action {
      none {}
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = "sql-injection"
      sampled_requests_enabled   = true
    }
  }

  # XSS ì°¨ë‹¨
  rule {
    name     = "xss"
    priority = 3

    statement {
      managed_rule_group_statement {
        vendor_name = "AWS"
        name        = "AWSManagedRulesKnownBadInputsRuleSet"
      }
    }

    override_action {
      none {}
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = "xss"
      sampled_requests_enabled   = true
    }
  }

  visibility_config {
    cloudwatch_metrics_enabled = true
    metric_name                = "invokeai-waf"
    sampled_requests_enabled   = true
  }
}

# WAFì™€ ALB ì—°ê²°
resource "aws_wafv2_web_acl_association" "main" {
  resource_arn = aws_lb.main.arn
  web_acl_arn  = aws_wafv2_web_acl.main.arn
}
```

### 8.2 Secrets ê´€ë¦¬

```python
# invokeai/app/util/secrets.py
import boto3
import json
from functools import lru_cache


class SecretsManager:
    """AWS Secrets Manager í†µí•©"""

    def __init__(self, region: str = "us-east-1"):
        self._client = boto3.client("secretsmanager", region_name=region)

    @lru_cache(maxsize=128)
    def get_secret(self, secret_name: str) -> dict:
        """Secret ì¡°íšŒ (ìºì‹œë¨)"""

        response = self._client.get_secret_value(SecretId=secret_name)

        if "SecretString" in response:
            return json.loads(response["SecretString"])
        else:
            # Binary secret
            return response["SecretBinary"]


# ì‚¬ìš© ì˜ˆì‹œ
secrets = SecretsManager()

db_credentials = secrets.get_secret("invokeai/database")
# {"username": "admin", "password": "..."}

stripe_key = secrets.get_secret("invokeai/stripe")
# {"secret_key": "sk_live_..."}
```

### 8.3 ë°ì´í„° ì•”í˜¸í™”

**1) ì „ì†¡ ì¤‘ ì•”í˜¸í™” (TLS):**

```hcl
# ALBì—ì„œ TLS 1.2+ ê°•ì œ
resource "aws_lb_listener" "https" {
  # ...
  ssl_policy = "ELBSecurityPolicy-TLS-1-2-2017-01"
}

# RDS - SSL ì—°ê²° ê°•ì œ
resource "aws_db_instance" "main" {
  # ...
  ca_cert_identifier = "rds-ca-2019"
}
```

**2) ì €ì¥ ì‹œ ì•”í˜¸í™”:**

```hcl
# S3 - ì„œë²„ ì‚¬ì´ë“œ ì•”í˜¸í™”
resource "aws_s3_bucket_server_side_encryption_configuration" "images" {
  bucket = aws_s3_bucket.images.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm     = "aws:kms"
      kms_master_key_id = aws_kms_key.s3.id
    }
  }
}

# RDS - ì•”í˜¸í™” í™œì„±í™”
resource "aws_db_instance" "main" {
  # ...
  storage_encrypted = true
  kms_key_id        = aws_kms_key.rds.arn
}

# EBS (GPU ì›Œì»¤) - ì•”í˜¸í™”
resource "aws_launch_template" "gpu_worker" {
  # ...
  block_device_mappings {
    device_name = "/dev/sda1"
    ebs {
      encrypted   = true
      kms_key_id  = aws_kms_key.ebs.arn
    }
  }
}
```

### 8.4 GDPR/ê°œì¸ì •ë³´ ë³´í˜¸

```python
# invokeai/app/api/routers/user.py
@router.delete("/me")
async def delete_account(
    user: TokenData = Depends(get_current_user),
    user_service: UserService = Depends(ApiDependencies.user_service),
):
    """
    ê³„ì • ì‚­ì œ (GDPR Right to be Forgotten)

    ëª¨ë“  ê°œì¸ ë°ì´í„° ì‚­ì œ
    """

    # 1. Stripe êµ¬ë… ì·¨ì†Œ
    if user.stripe_subscription_id:
        stripe.Subscription.delete(user.stripe_subscription_id)

    # 2. S3ì—ì„œ ëª¨ë“  ì´ë¯¸ì§€ ì‚­ì œ
    await delete_user_s3_data(user.user_id)

    # 3. DBì—ì„œ ê°œì¸ì •ë³´ ì œê±°
    await user_service.anonymize_user(user.user_id)

    # 4. ê°ì‚¬ ë¡œê·¸
    logger.info(f"User account deleted: {user.user_id}")

    return {"status": "deleted"}


@router.get("/me/data")
async def export_data(
    user: TokenData = Depends(get_current_user),
):
    """
    ë°ì´í„° ë‚´ë³´ë‚´ê¸° (GDPR Data Portability)

    ëª¨ë“  ê°œì¸ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜
    """

    data = {
        "user": {...},
        "images": [...],
        "workflows": [...],
        "subscription": {...},
    }

    return StreamingResponse(
        iter([json.dumps(data)]),
        media_type="application/json",
        headers={
            "Content-Disposition": "attachment; filename=my_data.json"
        },
    )
```

---

## ìš”ì•½ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ëŸ°ì¹˜ ì „ í•„ìˆ˜ í•­ëª©

- [ ] **ì¸ì¦ ë° ê¶Œí•œ**
  - [ ] AWS Cognito ì„¤ì •
  - [ ] JWT ê²€ì¦ êµ¬í˜„
  - [ ] ì‚¬ìš©ìë³„ ë°ì´í„° ê²©ë¦¬

- [ ] **ì¸í”„ë¼**
  - [ ] VPC ë° ì„œë¸Œë„· êµ¬ì„±
  - [ ] RDS PostgreSQL ì„¤ì •
  - [ ] S3 ë²„í‚· ìƒì„±
  - [ ] ElastiCache Redis ì„¤ì •
  - [ ] ECS Fargate ë°°í¬
  - [ ] GPU ì›Œì»¤ Auto Scaling

- [ ] **ê²°ì œ**
  - [ ] Stripe í†µí•©
  - [ ] Webhook ì„¤ì •
  - [ ] í• ë‹¹ëŸ‰ ì‹œìŠ¤í…œ

- [ ] **ëª¨ë‹ˆí„°ë§**
  - [ ] CloudWatch ëŒ€ì‹œë³´ë“œ
  - [ ] ì•ŒëŒ ì„¤ì •
  - [ ] Sentry ì—ëŸ¬ ì¶”ì 

- [ ] **ë³´ì•ˆ**
  - [ ] WAF ì„¤ì •
  - [ ] SSL/TLS ì¸ì¦ì„œ
  - [ ] Secrets Manager
  - [ ] ì•”í˜¸í™” (ì „ì†¡/ì €ì¥)

- [ ] **ìš´ì˜**
  - [ ] CI/CD íŒŒì´í”„ë¼ì¸
  - [ ] ë°±ì—… ì „ëµ
  - [ ] ì¬í•´ ë³µêµ¬ ê³„íš
  - [ ] ë¬¸ì„œí™”

### ì˜ˆìƒ ë¹„ìš© (ì›”ê°„)

| í•­ëª© | ë¹„ìš© |
|-----|------|
| ì»´í“¨íŒ… (ECS + GPU) | $500-800 |
| ë°ì´í„°ë² ì´ìŠ¤ | $70 |
| ìŠ¤í† ë¦¬ì§€ (S3) | $50 |
| ë„¤íŠ¸ì›Œí¬ | $100 |
| ê¸°íƒ€ | $50 |
| **ì´ê³„** | **$770-1070/ì›”** |

*ì‚¬ìš©ëŸ‰ì— ë”°ë¼ ë³€ë™

---

ì¶•í•˜í•©ë‹ˆë‹¤! ì´ì œ InvokeAIë¥¼ êµ¬ë…í˜• SaaSë¡œ ì „í™˜í•˜ëŠ” ëª¨ë“  ë‹¨ê³„ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤! ğŸ‰
