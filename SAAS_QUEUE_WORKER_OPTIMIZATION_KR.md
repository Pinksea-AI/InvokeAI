# InvokeAI SaaS - ë¹„ìš© ìµœì í™” Queue/Worker ì‹œìŠ¤í…œ ì„¤ê³„

> ë™ì ‘ 100ëª… ëŒ€ì‘ ê°€ëŠ¥í•œ ë¹„ìš© íš¨ìœ¨ì ì´ê³  ì•ˆì •ì ì¸ ì‘ì—… í ì‹œìŠ¤í…œ

## ğŸ“‹ ëª©ì°¨

1. [ì•„í‚¤í…ì²˜ ê°œìš”](#1-ì•„í‚¤í…ì²˜-ê°œìš”)
2. [ìš©ëŸ‰ ê³„íš](#2-ìš©ëŸ‰-ê³„íš)
3. [SQS ê¸°ë°˜ ë©”ì‹œì§€ í](#3-sqs-ê¸°ë°˜-ë©”ì‹œì§€-í)
4. [GPU ì›Œì»¤ Auto Scaling](#4-gpu-ì›Œì»¤-auto-scaling)
5. [Lambda ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜](#5-lambda-ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜)
6. [OOM ë°©ì§€ ì „ëµ](#6-oom-ë°©ì§€-ì „ëµ)
7. [ëª¨ë‹ˆí„°ë§ ë° ì•ŒëŒ](#7-ëª¨ë‹ˆí„°ë§-ë°-ì•ŒëŒ)
8. [ë¹„ìš© ë¶„ì„](#8-ë¹„ìš©-ë¶„ì„)
9. [ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ](#9-ë‹¨ê³„ë³„-êµ¬í˜„-ê°€ì´ë“œ)
10. [í…ŒìŠ¤íŠ¸ ë° ê²€ì¦](#10-í…ŒìŠ¤íŠ¸-ë°-ê²€ì¦)

---

## 1. ì•„í‚¤í…ì²˜ ê°œìš”

### 1.1 ë¹„ìš© ìµœì í™” ì„¤ê³„ ì›ì¹™

**í•µì‹¬ ì•„ì´ë””ì–´:**
- GPU ì›Œì»¤ëŠ” ì‘ì—…ì´ ìˆì„ ë•Œë§Œ ì‹¤í–‰ (ìœ íœ´ ì‹œê°„ 0)
- Spot ì¸ìŠ¤í„´ìŠ¤ë¡œ 70% ë¹„ìš© ì ˆê°
- ì™„ì „ ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ í™œìš© (ìš´ì˜ ë¶€ë‹´ ìµœì†Œí™”)
- Pay-per-use ëª¨ë¸

### 1.2 ì „ì²´ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ì‚¬ìš©ì ìš”ì²­                                â”‚
â”‚              (ì´ë¯¸ì§€ ìƒì„± API í˜¸ì¶œ)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI Server (ECS Fargate)                   â”‚
â”‚  - ìš”ì²­ ê²€ì¦ (í• ë‹¹ëŸ‰, í”Œëœ)                                   â”‚
â”‚  - SQSì— ë©”ì‹œì§€ ì „ì†¡                                          â”‚
â”‚  - Task ID ë°˜í™˜                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ â‘  ì‘ì—… ë©”ì‹œì§€ ì „ì†¡
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Amazon SQS (3ê°œ í)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ High Priorityâ”‚  â”‚Med Priority  â”‚  â”‚ Low Priority â”‚      â”‚
â”‚  â”‚ (Enterprise) â”‚  â”‚ (Pro)        â”‚  â”‚ (Free)       â”‚      â”‚
â”‚  â”‚ FIFO Queue   â”‚  â”‚ Standard     â”‚  â”‚ Standard     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ â‘¡ Queue depth ëª¨ë‹ˆí„°ë§
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          CloudWatch Alarm + Lambda (Scaler)                 â”‚
â”‚  - Queue ê¸¸ì´ ì²´í¬ (ë§¤ 1ë¶„)                                  â”‚
â”‚  - í•„ìš” ì›Œì»¤ ìˆ˜ ê³„ì‚°                                          â”‚
â”‚  - Auto Scaling Group ì¡°ì •                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ â‘¢ EC2 Spot GPU ì¸ìŠ¤í„´ìŠ¤ ì‹¤í–‰
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Auto Scaling Group (GPU Workers)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  EC2 g5.xlarge Spot (1 GPU per instance)         â”‚      â”‚
â”‚  â”‚  - Min: 0 (ì‘ì—… ì—†ìœ¼ë©´ 0ê°œ)                       â”‚      â”‚
â”‚  â”‚  - Max: 10 (ë™ì ‘ 100ëª… ëŒ€ì‘)                      â”‚      â”‚
â”‚  â”‚  - Desired: Auto-calculated                       â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                              â”‚
â”‚  ê° ì›Œì»¤:                                                    â”‚
â”‚  - SQS Polling (long polling 20ì´ˆ)                          â”‚
â”‚  - ì‘ì—… ì²˜ë¦¬ (ì´ë¯¸ì§€ ìƒì„±)                                   â”‚
â”‚  - S3 ì—…ë¡œë“œ                                                 â”‚
â”‚  - DynamoDB ìƒíƒœ ì—…ë°ì´íŠ¸                                    â”‚
â”‚  - ìœ íœ´ 5ë¶„ â†’ ìë™ ì¢…ë£Œ                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ â‘£ ê²°ê³¼ ì €ì¥
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ê²°ê³¼ ì €ì¥ì†Œ                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚      S3      â”‚  â”‚  DynamoDB    â”‚                        â”‚
â”‚  â”‚  (ì´ë¯¸ì§€)    â”‚  â”‚  (ì‘ì—… ìƒíƒœ) â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ â‘¤ WebSocket or Polling
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ì‚¬ìš©ì ì•±                                  â”‚
â”‚  - ì‘ì—… ìƒíƒœ ì¡°íšŒ (polling)                                  â”‚
â”‚  - ì™„ë£Œ ì‹œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 ê¸°ì¡´ Redis/Celery vs ìƒˆë¡œìš´ SQS/ASG ë¹„êµ

| í•­ëª© | Redis + Celery | SQS + ASG (ì œì•ˆ) |
|-----|----------------|------------------|
| **ë©”ì‹œì§€ í** | ElastiCache Redis ($45/ì›”) | SQS ($0.40/100ë§Œ ìš”ì²­) |
| **ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬** | Celery (ì§ì ‘ ê´€ë¦¬) | Lambda + CloudWatch ($0) |
| **GPU ì›Œì»¤** | 24ì‹œê°„ ì‹¤í–‰ (ìµœì†Œ 1ê°œ) | ì‚¬ìš© ì‹œì—ë§Œ ì‹¤í–‰ (0-10ê°œ) |
| **ìŠ¤ì¼€ì¼ë§** | ìˆ˜ë™ ë˜ëŠ” HPA | ì™„ì „ ìë™ (1ë¶„ ë‹¨ìœ„) |
| **ìœ íœ´ ì‹œ ë¹„ìš©** | ~$500/ì›” (g5.xlarge 1ëŒ€) | $0 (ì¸ìŠ¤í„´ìŠ¤ 0ê°œ) |
| **ë³µì¡ë„** | ë†’ìŒ (Celery ì„¤ì •, ëª¨ë‹ˆí„°ë§) | ë‚®ìŒ (AWS ê´€ë¦¬) |
| **ê°€ìš©ì„±** | Single point of failure | ë‹¤ì¤‘ AZ, Spot ì¬ì‹œë„ |
| **ë©”ì‹œì§€ ë³´ì¡´** | ì œí•œì  (ë©”ëª¨ë¦¬) | 14ì¼ (SQS ê¸°ë³¸) |

**ë¹„ìš© ì ˆê° íš¨ê³¼:**
- ì•¼ê°„/ì£¼ë§ íŠ¸ë˜í”½ ì—†ì„ ë•Œ: **$500 â†’ $0** (100% ì ˆê°)
- í”¼í¬ ì‹œê°„ (ë™ì ‘ 100ëª…): **$500 â†’ $150** (70% ì ˆê°, Spot)

---

## 2. ìš©ëŸ‰ ê³„íš

### 2.1 ì›Œí¬ë¡œë“œ ë¶„ì„

**ë™ì ‘ 100ëª… ì‹œë‚˜ë¦¬ì˜¤:**

```
ê°€ì •:
- ë™ì‹œ ì‚¬ìš©ì: 100ëª…
- í‰ê·  ì´ë¯¸ì§€ ìƒì„± ìš”ì²­: 10ì¥/ì‹œê°„/ì‚¬ìš©ì
- ì´ ìš”ì²­: 1000ì¥/ì‹œê°„ = ~0.28ì¥/ì´ˆ

ì´ë¯¸ì§€ ìƒì„± ì‹œê°„ (ëª¨ë¸ë³„):
- SD 1.5 (512x512): 10ì´ˆ
- SDXL (1024x1024): 30ì´ˆ
- FLUX (1024x1024): 45ì´ˆ

ìµœì•…ì˜ ê²½ìš° (ëª¨ë‘ FLUX):
- 1000ì¥/ì‹œê°„ Ã— 45ì´ˆ = 45,000ì´ˆ
- í•„ìš” GPU ì‹œê°„: 45,000ì´ˆ / 3600ì´ˆ = 12.5 GPU-hour
- í•„ìš” ì›Œì»¤ ìˆ˜: 12.5ê°œ (ì—°ì† ì‘ì—… ì‹œ)
```

### 2.2 í ì„¤ê³„

```python
# íë³„ ì²˜ë¦¬ ì „ëµ
HIGH_PRIORITY_QUEUE = {
    "name": "invokeai-tasks-high",
    "type": "FIFO",  # ìˆœì„œ ë³´ì¥
    "plan": "enterprise",
    "delay": "0ì´ˆ",
    "timeout": "120ì´ˆ",  # 2ë¶„
}

MEDIUM_PRIORITY_QUEUE = {
    "name": "invokeai-tasks-medium",
    "type": "Standard",
    "plan": "pro",
    "delay": "0ì´ˆ",
    "timeout": "180ì´ˆ",  # 3ë¶„
}

LOW_PRIORITY_QUEUE = {
    "name": "invokeai-tasks-low",
    "type": "Standard",
    "plan": "free",
    "delay": "5ì´ˆ",  # ì•½ê°„ì˜ ì§€ì—°
    "timeout": "300ì´ˆ",  # 5ë¶„
}
```

### 2.3 ì›Œì»¤ Auto Scaling ë£°

```python
# Queue depthì— ë”°ë¥¸ ì›Œì»¤ ìˆ˜ ê³„ì‚°
def calculate_required_workers(queue_depths, avg_processing_time=30):
    """
    í•„ìš”í•œ ì›Œì»¤ ìˆ˜ ê³„ì‚°

    Args:
        queue_depths: {queue_name: depth}
        avg_processing_time: í‰ê·  ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)

    Returns:
        int: í•„ìš”í•œ ì›Œì»¤ ìˆ˜
    """
    total_messages = sum(queue_depths.values())

    # ëª©í‘œ: 15ë¶„ ì´ë‚´ì— ëª¨ë“  ì‘ì—… ì²˜ë¦¬
    target_completion_time = 900  # 15ë¶„

    # í•„ìš” ì›Œì»¤ = (ì´ ë©”ì‹œì§€ ìˆ˜ Ã— í‰ê·  ì²˜ë¦¬ ì‹œê°„) / ëª©í‘œ ì™„ë£Œ ì‹œê°„
    required_workers = (total_messages * avg_processing_time) / target_completion_time

    # ìµœì†Œ 0, ìµœëŒ€ 10
    return max(0, min(10, int(required_workers) + 1))


# ì˜ˆì‹œ:
queue_depths = {
    "high": 5,    # Enterprise: 5ê°œ ëŒ€ê¸°
    "medium": 20, # Pro: 20ê°œ ëŒ€ê¸°
    "low": 50,    # Free: 50ê°œ ëŒ€ê¸°
}

required = calculate_required_workers(queue_depths)
# (75 Ã— 30) / 900 = 2.5 â†’ 3 workers
```

---

## 3. SQS ê¸°ë°˜ ë©”ì‹œì§€ í

### 3.1 Terraformìœ¼ë¡œ SQS ìƒì„±

```hcl
# terraform/sqs.tf

# High Priority Queue (FIFO - Enterprise)
resource "aws_sqs_queue" "high_priority" {
  name                        = "invokeai-tasks-high.fifo"
  fifo_queue                  = true
  content_based_deduplication = true

  visibility_timeout_seconds  = 120  # 2ë¶„
  message_retention_seconds   = 1209600  # 14ì¼
  max_message_size            = 262144  # 256KB
  delay_seconds              = 0
  receive_wait_time_seconds  = 20  # Long polling

  # DLQ (Dead Letter Queue)
  redrive_policy = jsonencode({
    deadLetterTargetArn = aws_sqs_queue.dlq.arn
    maxReceiveCount     = 3  # 3ë²ˆ ì‹¤íŒ¨ ì‹œ DLQë¡œ
  })

  tags = {
    Environment = "production"
    Priority    = "high"
    Plan        = "enterprise"
  }
}

# Medium Priority Queue (Standard - Pro)
resource "aws_sqs_queue" "medium_priority" {
  name                       = "invokeai-tasks-medium"
  fifo_queue                 = false

  visibility_timeout_seconds = 180  # 3ë¶„
  message_retention_seconds  = 1209600
  max_message_size           = 262144
  delay_seconds             = 0
  receive_wait_time_seconds = 20

  redrive_policy = jsonencode({
    deadLetterTargetArn = aws_sqs_queue.dlq.arn
    maxReceiveCount     = 3
  })

  tags = {
    Environment = "production"
    Priority    = "medium"
    Plan        = "pro"
  }
}

# Low Priority Queue (Standard - Free)
resource "aws_sqs_queue" "low_priority" {
  name                       = "invokeai-tasks-low"
  fifo_queue                 = false

  visibility_timeout_seconds = 300  # 5ë¶„
  message_retention_seconds  = 1209600
  max_message_size           = 262144
  delay_seconds             = 5  # 5ì´ˆ ì§€ì—°
  receive_wait_time_seconds = 20

  redrive_policy = jsonencode({
    deadLetterTargetArn = aws_sqs_queue.dlq.arn
    maxReceiveCount     = 3
  })

  tags = {
    Environment = "production"
    Priority    = "low"
    Plan        = "free"
  }
}

# Dead Letter Queue
resource "aws_sqs_queue" "dlq" {
  name                      = "invokeai-tasks-dlq"
  message_retention_seconds = 1209600

  tags = {
    Environment = "production"
    Type        = "dlq"
  }
}

# CloudWatch Alarms for Queue Depth
resource "aws_cloudwatch_metric_alarm" "high_queue_depth" {
  alarm_name          = "invokeai-high-queue-depth"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 1
  metric_name         = "ApproximateNumberOfMessagesVisible"
  namespace           = "AWS/SQS"
  period              = 60  # 1ë¶„
  statistic           = "Average"
  threshold           = 5
  alarm_description   = "High priority queue has more than 5 messages"

  dimensions = {
    QueueName = aws_sqs_queue.high_priority.name
  }

  alarm_actions = [aws_sns_topic.scaling_alerts.arn]
}

resource "aws_cloudwatch_metric_alarm" "medium_queue_depth" {
  alarm_name          = "invokeai-medium-queue-depth"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 1
  metric_name         = "ApproximateNumberOfMessagesVisible"
  namespace           = "AWS/SQS"
  period              = 60
  statistic           = "Average"
  threshold           = 10

  dimensions = {
    QueueName = aws_sqs_queue.medium_priority.name
  }

  alarm_actions = [aws_sns_topic.scaling_alerts.arn]
}
```

### 3.2 FastAPIì—ì„œ SQSë¡œ ë©”ì‹œì§€ ì „ì†¡

```python
# invokeai/app/services/queue_service.py
import boto3
import json
import hashlib
from typing import Dict, Any
from datetime import datetime

class SQSQueueService:
    def __init__(self, region: str = "us-east-1"):
        self.sqs = boto3.client("sqs", region_name=region)

        # Queue URLs
        self.queue_urls = {
            "enterprise": "https://sqs.us-east-1.amazonaws.com/123456789/invokeai-tasks-high.fifo",
            "pro": "https://sqs.us-east-1.amazonaws.com/123456789/invokeai-tasks-medium",
            "free": "https://sqs.us-east-1.amazonaws.com/123456789/invokeai-tasks-low",
        }

    def send_task(
        self,
        user_id: str,
        task_id: str,
        plan: str,
        task_data: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        ì‘ì—…ì„ SQSì— ì „ì†¡

        Args:
            user_id: ì‚¬ìš©ì ID
            task_id: ì‘ì—… ID (UUID)
            plan: êµ¬ë… í”Œëœ (enterprise/pro/free)
            task_data: ì‘ì—… ë°ì´í„°

        Returns:
            SQS ì‘ë‹µ
        """
        queue_url = self.queue_urls.get(plan, self.queue_urls["free"])

        # ë©”ì‹œì§€ ë³¸ë¬¸
        message_body = {
            "task_id": task_id,
            "user_id": user_id,
            "plan": plan,
            "timestamp": datetime.utcnow().isoformat(),
            "task_type": "image_generation",
            "data": task_data,
        }

        # FIFO íì¸ ê²½ìš° ì¶”ê°€ íŒŒë¼ë¯¸í„° í•„ìš”
        if plan == "enterprise":
            # Message Group ID: ì‚¬ìš©ìë³„ë¡œ ê·¸ë£¹í™” (ë™ì¼ ì‚¬ìš©ìì˜ ì‘ì—…ì€ ìˆœì„œ ë³´ì¥)
            message_group_id = f"user-{user_id}"

            # Message Deduplication ID: ì¤‘ë³µ ë°©ì§€
            dedup_id = hashlib.sha256(
                f"{task_id}-{user_id}-{datetime.utcnow().isoformat()}".encode()
            ).hexdigest()

            response = self.sqs.send_message(
                QueueUrl=queue_url,
                MessageBody=json.dumps(message_body),
                MessageGroupId=message_group_id,
                MessageDeduplicationId=dedup_id,
            )
        else:
            # Standard í
            response = self.sqs.send_message(
                QueueUrl=queue_url,
                MessageBody=json.dumps(message_body),
            )

        return response

    def get_queue_depth(self, plan: str) -> int:
        """íì˜ í˜„ì¬ ë©”ì‹œì§€ ìˆ˜ ì¡°íšŒ"""
        queue_url = self.queue_urls.get(plan)

        response = self.sqs.get_queue_attributes(
            QueueUrl=queue_url,
            AttributeNames=["ApproximateNumberOfMessages"]
        )

        return int(response["Attributes"]["ApproximateNumberOfMessages"])
```

### 3.3 API ì—”ë“œí¬ì¸íŠ¸ ìˆ˜ì •

```python
# invokeai/app/api/routers/images.py
from fastapi import APIRouter, Depends, HTTPException
from invokeai.app.services.queue_service import SQSQueueService
from invokeai.app.services.subscription import get_user_plan, check_quota
import uuid

router = APIRouter(prefix="/api/v1/images", tags=["images"])

@router.post("/generate")
async def generate_image(
    prompt: str,
    negative_prompt: str = "",
    width: int = 1024,
    height: int = 1024,
    steps: int = 30,
    user_id: str = Depends(get_current_user_id),
    queue_service: SQSQueueService = Depends(get_queue_service),
):
    """
    ì´ë¯¸ì§€ ìƒì„± ìš”ì²­

    1. ì‚¬ìš©ì í• ë‹¹ëŸ‰ ì²´í¬
    2. SQSì— ì‘ì—… ì „ì†¡
    3. Task ID ë°˜í™˜
    """
    # 1. í• ë‹¹ëŸ‰ ì²´í¬
    plan = await get_user_plan(user_id)
    quota_ok = await check_quota(user_id, plan)

    if not quota_ok:
        raise HTTPException(
            status_code=429,
            detail="Monthly quota exceeded. Please upgrade your plan."
        )

    # 2. Task ID ìƒì„±
    task_id = str(uuid.uuid4())

    # 3. Task ë°ì´í„° ì¤€ë¹„
    task_data = {
        "prompt": prompt,
        "negative_prompt": negative_prompt,
        "width": width,
        "height": height,
        "steps": steps,
        "model": "sdxl",  # ê¸°ë³¸ ëª¨ë¸
    }

    # 4. SQSì— ì „ì†¡
    try:
        response = queue_service.send_task(
            user_id=user_id,
            task_id=task_id,
            plan=plan,
            task_data=task_data,
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to queue task: {str(e)}")

    # 5. DynamoDBì— ì‘ì—… ìƒíƒœ ì´ˆê¸°í™”
    await save_task_status(
        task_id=task_id,
        user_id=user_id,
        status="queued",
        created_at=datetime.utcnow(),
    )

    return {
        "task_id": task_id,
        "status": "queued",
        "message": "Image generation task queued successfully",
        "estimated_wait_time_seconds": await estimate_wait_time(plan),
    }


@router.get("/tasks/{task_id}")
async def get_task_status(
    task_id: str,
    user_id: str = Depends(get_current_user_id),
):
    """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    task = await get_task_from_dynamodb(task_id, user_id)

    if not task:
        raise HTTPException(status_code=404, detail="Task not found")

    return {
        "task_id": task_id,
        "status": task["status"],  # queued, processing, completed, failed
        "progress": task.get("progress", 0),
        "image_url": task.get("image_url"),
        "error": task.get("error"),
        "created_at": task["created_at"],
        "completed_at": task.get("completed_at"),
    }
```

---

## 4. GPU ì›Œì»¤ Auto Scaling

### 4.1 Launch Template (GPU EC2)

```hcl
# terraform/gpu_worker.tf

# Launch Template for GPU Workers
resource "aws_launch_template" "gpu_worker" {
  name_prefix   = "invokeai-gpu-worker-"
  image_id      = "ami-0abcdef1234567890"  # Deep Learning AMI (Ubuntu, NVIDIA GPU)
  instance_type = "g5.xlarge"

  # Spot ì¸ìŠ¤í„´ìŠ¤ ìš”ì²­
  instance_market_options {
    market_type = "spot"
    spot_options {
      max_price          = "0.50"  # ì‹œê°„ë‹¹ ìµœëŒ€ $0.50 (On-Demandì˜ ~50%)
      spot_instance_type = "one-time"
    }
  }

  # IAM ì—­í•  (S3, SQS, DynamoDB ì ‘ê·¼)
  iam_instance_profile {
    name = aws_iam_instance_profile.gpu_worker.name
  }

  # ë³´ì•ˆ ê·¸ë£¹
  vpc_security_group_ids = [aws_security_group.gpu_worker.id]

  # User Data (ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸)
  user_data = base64encode(templatefile("${path.module}/user_data.sh", {
    region           = var.aws_region
    high_queue_url   = aws_sqs_queue.high_priority.url
    medium_queue_url = aws_sqs_queue.medium_priority.url
    low_queue_url    = aws_sqs_queue.low_priority.url
    s3_bucket        = aws_s3_bucket.images.bucket
  }))

  # EBS ë³¼ë¥¨ (ëª¨ë¸ ì €ì¥)
  block_device_mappings {
    device_name = "/dev/sda1"
    ebs {
      volume_size           = 100  # 100GB (ëª¨ë¸ìš©)
      volume_type           = "gp3"
      delete_on_termination = true
      encrypted             = true
    }
  }

  # íƒœê·¸
  tag_specifications {
    resource_type = "instance"
    tags = {
      Name        = "invokeai-gpu-worker"
      Environment = "production"
      ManagedBy   = "terraform"
    }
  }

  tags = {
    Name = "invokeai-gpu-worker-template"
  }
}

# Auto Scaling Group
resource "aws_autoscaling_group" "gpu_workers" {
  name                = "invokeai-gpu-workers"
  vpc_zone_identifier = [
    aws_subnet.private_app_a.id,
    aws_subnet.private_app_b.id,
    aws_subnet.private_app_c.id,
  ]

  min_size         = 0  # ìµœì†Œ 0ê°œ (ë¹„ìš© ì ˆê°)
  max_size         = 10  # ìµœëŒ€ 10ê°œ (ë™ì ‘ 100ëª… ëŒ€ì‘)
  desired_capacity = 0  # ì´ˆê¸° 0ê°œ

  health_check_type         = "EC2"
  health_check_grace_period = 300  # 5ë¶„
  default_cooldown          = 60   # 1ë¶„

  launch_template {
    id      = aws_launch_template.gpu_worker.id
    version = "$Latest"
  }

  # ì¸ìŠ¤í„´ìŠ¤ ì¬ì‚¬ìš© ì •ì±… (Spot ì¤‘ë‹¨ ì‹œ)
  instance_refresh {
    strategy = "Rolling"
    preferences {
      min_healthy_percentage = 50
    }
  }

  # íƒœê·¸
  tag {
    key                 = "Name"
    value               = "invokeai-gpu-worker"
    propagate_at_launch = true
  }

  tag {
    key                 = "AutoScaling"
    value               = "enabled"
    propagate_at_launch = true
  }
}
```

### 4.2 Worker ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸ (User Data)

```bash
#!/bin/bash
# user_data.sh - GPU Worker ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸

set -e

# ë³€ìˆ˜
REGION="${region}"
HIGH_QUEUE_URL="${high_queue_url}"
MEDIUM_QUEUE_URL="${medium_queue_url}"
LOW_QUEUE_URL="${low_queue_url}"
S3_BUCKET="${s3_bucket}"

# ë¡œê·¸ ì„¤ì •
exec > >(tee /var/log/user-data.log)
exec 2>&1

echo "=== GPU Worker ì´ˆê¸°í™” ì‹œì‘ ==="
date

# 1. ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
apt-get update -y
apt-get install -y python3-pip awscli jq

# 2. NVIDIA Driver í™•ì¸
nvidia-smi
if [ $? -ne 0 ]; then
    echo "ERROR: NVIDIA Driver not found!"
    exit 1
fi

# 3. Python í™˜ê²½ ì„¤ì •
cd /opt
git clone https://github.com/your-repo/InvokeAI.git
cd InvokeAI

python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 4. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (S3ì—ì„œ)
echo "ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘..."
aws s3 sync s3://${S3_BUCKET}/models /opt/InvokeAI/models --region ${REGION}

# 5. Worker ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cat > /opt/InvokeAI/worker.py << 'EOF'
#!/usr/bin/env python3
"""
SQS GPU Worker
- SQSì—ì„œ ì‘ì—…ì„ í´ë§
- ì´ë¯¸ì§€ ìƒì„± í›„ S3 ì—…ë¡œë“œ
- DynamoDB ìƒíƒœ ì—…ë°ì´íŠ¸
"""

import os
import json
import boto3
import time
from datetime import datetime
from invokeai.app.services.image_generation import generate_image

# AWS í´ë¼ì´ì–¸íŠ¸
sqs = boto3.client('sqs', region_name=os.environ['AWS_REGION'])
s3 = boto3.client('s3', region_name=os.environ['AWS_REGION'])
dynamodb = boto3.resource('dynamodb', region_name=os.environ['AWS_REGION'])

# Queue URLs
QUEUES = [
    os.environ['HIGH_QUEUE_URL'],    # High priority
    os.environ['MEDIUM_QUEUE_URL'],  # Medium priority
    os.environ['LOW_QUEUE_URL'],     # Low priority
]

# DynamoDB Table
tasks_table = dynamodb.Table('invokeai-tasks')

# ìœ íœ´ íƒ€ì´ë¨¸
IDLE_TIMEOUT = 300  # 5ë¶„ ìœ íœ´ ì‹œ ì¢…ë£Œ
last_activity = time.time()


def poll_queues():
    """ìš°ì„ ìˆœìœ„ ìˆœì„œëŒ€ë¡œ í í´ë§"""
    for queue_url in QUEUES:
        messages = sqs.receive_message(
            QueueUrl=queue_url,
            MaxNumberOfMessages=1,
            WaitTimeSeconds=20,  # Long polling
            VisibilityTimeout=120,  # 2ë¶„
        )

        if 'Messages' in messages:
            return messages['Messages'][0], queue_url

    return None, None


def process_task(message, queue_url):
    """ì‘ì—… ì²˜ë¦¬"""
    global last_activity
    last_activity = time.time()

    body = json.loads(message['Body'])
    task_id = body['task_id']
    user_id = body['user_id']
    task_data = body['data']

    print(f"[{datetime.now()}] Processing task {task_id} for user {user_id}")

    try:
        # DynamoDB ìƒíƒœ ì—…ë°ì´íŠ¸: processing
        tasks_table.update_item(
            Key={'task_id': task_id, 'user_id': user_id},
            UpdateExpression="SET #status = :status, started_at = :started",
            ExpressionAttributeNames={'#status': 'status'},
            ExpressionAttributeValues={
                ':status': 'processing',
                ':started': datetime.utcnow().isoformat(),
            }
        )

        # ì´ë¯¸ì§€ ìƒì„±
        image_bytes = generate_image(
            prompt=task_data['prompt'],
            negative_prompt=task_data.get('negative_prompt', ''),
            width=task_data['width'],
            height=task_data['height'],
            steps=task_data['steps'],
        )

        # S3 ì—…ë¡œë“œ
        s3_key = f"images/{user_id}/{task_id}.png"
        s3.put_object(
            Bucket=os.environ['S3_BUCKET'],
            Key=s3_key,
            Body=image_bytes,
            ContentType='image/png',
        )

        image_url = f"https://{os.environ['S3_BUCKET']}.s3.amazonaws.com/{s3_key}"

        # DynamoDB ìƒíƒœ ì—…ë°ì´íŠ¸: completed
        tasks_table.update_item(
            Key={'task_id': task_id, 'user_id': user_id},
            UpdateExpression="SET #status = :status, image_url = :url, completed_at = :completed",
            ExpressionAttributeNames={'#status': 'status'},
            ExpressionAttributeValues={
                ':status': 'completed',
                ':url': image_url,
                ':completed': datetime.utcnow().isoformat(),
            }
        )

        # SQS ë©”ì‹œì§€ ì‚­ì œ
        sqs.delete_message(
            QueueUrl=queue_url,
            ReceiptHandle=message['ReceiptHandle']
        )

        print(f"[{datetime.now()}] Task {task_id} completed successfully")

    except Exception as e:
        print(f"[{datetime.now()}] ERROR processing task {task_id}: {str(e)}")

        # DynamoDB ìƒíƒœ ì—…ë°ì´íŠ¸: failed
        tasks_table.update_item(
            Key={'task_id': task_id, 'user_id': user_id},
            UpdateExpression="SET #status = :status, error = :error",
            ExpressionAttributeNames={'#status': 'status'},
            ExpressionAttributeValues={
                ':status': 'failed',
                ':error': str(e),
            }
        )

        # ë©”ì‹œì§€ ì‚­ì œí•˜ì§€ ì•ŠìŒ (DLQë¡œ ì´ë™ë  ìˆ˜ ìˆë„ë¡)


def main():
    """ë©”ì¸ ë£¨í”„"""
    global last_activity

    print(f"[{datetime.now()}] GPU Worker started")

    while True:
        # í í´ë§
        message, queue_url = poll_queues()

        if message:
            # ì‘ì—… ì²˜ë¦¬
            process_task(message, queue_url)
        else:
            # ìœ íœ´ ìƒíƒœ
            idle_time = time.time() - last_activity

            if idle_time > IDLE_TIMEOUT:
                print(f"[{datetime.now()}] Idle timeout ({IDLE_TIMEOUT}s). Shutting down...")

                # ìê¸° ìì‹  ì¢…ë£Œ (Auto Scalingì´ ê´€ë¦¬)
                instance_id = os.popen('ec2-metadata --instance-id | cut -d " " -f 2').read().strip()

                autoscaling = boto3.client('autoscaling', region_name=os.environ['AWS_REGION'])
                autoscaling.terminate_instance_in_auto_scaling_group(
                    InstanceId=instance_id,
                    ShouldDecrementDesiredCapacity=True
                )
                break

            print(f"[{datetime.now()}] No tasks. Idle for {int(idle_time)}s / {IDLE_TIMEOUT}s")
            time.sleep(5)


if __name__ == '__main__':
    main()
EOF

chmod +x /opt/InvokeAI/worker.py

# 6. Systemd ì„œë¹„ìŠ¤ ìƒì„± (ìë™ ì‹œì‘)
cat > /etc/systemd/system/invokeai-worker.service << EOF
[Unit]
Description=InvokeAI GPU Worker
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/opt/InvokeAI
Environment="AWS_REGION=${REGION}"
Environment="HIGH_QUEUE_URL=${HIGH_QUEUE_URL}"
Environment="MEDIUM_QUEUE_URL=${MEDIUM_QUEUE_URL}"
Environment="LOW_QUEUE_URL=${LOW_QUEUE_URL}"
Environment="S3_BUCKET=${S3_BUCKET}"
ExecStart=/opt/InvokeAI/venv/bin/python /opt/InvokeAI/worker.py
Restart=on-failure
RestartSec=10

[Install]
WantedBy=multi-user.target
EOF

# 7. ì„œë¹„ìŠ¤ ì‹œì‘
systemctl daemon-reload
systemctl enable invokeai-worker
systemctl start invokeai-worker

echo "=== GPU Worker ì´ˆê¸°í™” ì™„ë£Œ ==="
date
```

### 4.3 Lambda Auto Scaler (í ëª¨ë‹ˆí„°ë§ ë° ìŠ¤ì¼€ì¼ë§)

```python
# lambda/auto_scaler.py
"""
Lambda Function: GPU Worker Auto Scaler

CloudWatch Events (1ë¶„ë§ˆë‹¤):
- SQS í ê¹Šì´ í™•ì¸
- í•„ìš”í•œ ì›Œì»¤ ìˆ˜ ê³„ì‚°
- Auto Scaling Group desired capacity ì¡°ì •
"""

import boto3
import os
from datetime import datetime

sqs = boto3.client('sqs')
autoscaling = boto3.client('autoscaling')
cloudwatch = boto3.client('cloudwatch')

# í™˜ê²½ ë³€ìˆ˜
ASG_NAME = os.environ['ASG_NAME']
QUEUES = {
    'high': os.environ['HIGH_QUEUE_URL'],
    'medium': os.environ['MEDIUM_QUEUE_URL'],
    'low': os.environ['LOW_QUEUE_URL'],
}

# ì„¤ì •
AVG_PROCESSING_TIME = 30  # í‰ê·  ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)
TARGET_COMPLETION_TIME = 900  # ëª©í‘œ ì™„ë£Œ ì‹œê°„ (15ë¶„)
MIN_WORKERS = 0
MAX_WORKERS = 10


def get_queue_depth(queue_url):
    """íì˜ ë©”ì‹œì§€ ìˆ˜ ì¡°íšŒ"""
    response = sqs.get_queue_attributes(
        QueueUrl=queue_url,
        AttributeNames=['ApproximateNumberOfMessages']
    )
    return int(response['Attributes']['ApproximateNumberOfMessages'])


def calculate_required_workers(queue_depths):
    """í•„ìš”í•œ ì›Œì»¤ ìˆ˜ ê³„ì‚°"""
    total_messages = sum(queue_depths.values())

    if total_messages == 0:
        return 0

    # í•„ìš” ì›Œì»¤ = (ì´ ë©”ì‹œì§€ Ã— ì²˜ë¦¬ ì‹œê°„) / ëª©í‘œ ì™„ë£Œ ì‹œê°„
    required = (total_messages * AVG_PROCESSING_TIME) / TARGET_COMPLETION_TIME

    # ìµœì†Œ 1ê°œ (ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´), ìµœëŒ€ MAX_WORKERS
    return max(1, min(MAX_WORKERS, int(required) + 1))


def get_current_capacity():
    """í˜„ì¬ ASG capacity ì¡°íšŒ"""
    response = autoscaling.describe_auto_scaling_groups(
        AutoScalingGroupNames=[ASG_NAME]
    )

    if not response['AutoScalingGroups']:
        raise Exception(f"ASG {ASG_NAME} not found")

    asg = response['AutoScalingGroups'][0]
    return {
        'desired': asg['DesiredCapacity'],
        'current': len(asg['Instances']),
        'min': asg['MinSize'],
        'max': asg['MaxSize'],
    }


def set_desired_capacity(desired):
    """ASG desired capacity ì„¤ì •"""
    autoscaling.set_desired_capacity(
        AutoScalingGroupName=ASG_NAME,
        DesiredCapacity=desired,
        HonorCooldown=False  # ì¦‰ì‹œ ì ìš©
    )


def publish_metrics(queue_depths, required_workers, current_capacity):
    """CloudWatch ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ë°œí–‰"""
    cloudwatch.put_metric_data(
        Namespace='InvokeAI/Workers',
        MetricData=[
            {
                'MetricName': 'TotalQueueDepth',
                'Value': sum(queue_depths.values()),
                'Unit': 'Count',
                'Timestamp': datetime.utcnow(),
            },
            {
                'MetricName': 'RequiredWorkers',
                'Value': required_workers,
                'Unit': 'Count',
                'Timestamp': datetime.utcnow(),
            },
            {
                'MetricName': 'CurrentWorkers',
                'Value': current_capacity['current'],
                'Unit': 'Count',
                'Timestamp': datetime.utcnow(),
            },
        ]
    )


def lambda_handler(event, context):
    """Lambda í•¸ë“¤ëŸ¬"""
    print(f"[{datetime.now()}] Auto Scaler started")

    # 1. í ê¹Šì´ ì¡°íšŒ
    queue_depths = {}
    for priority, queue_url in QUEUES.items():
        depth = get_queue_depth(queue_url)
        queue_depths[priority] = depth
        print(f"  Queue {priority}: {depth} messages")

    # 2. í•„ìš”í•œ ì›Œì»¤ ìˆ˜ ê³„ì‚°
    required_workers = calculate_required_workers(queue_depths)
    print(f"  Required workers: {required_workers}")

    # 3. í˜„ì¬ capacity ì¡°íšŒ
    current_capacity = get_current_capacity()
    print(f"  Current capacity: {current_capacity}")

    # 4. capacity ì¡°ì • í•„ìš” ì—¬ë¶€ í™•ì¸
    if required_workers != current_capacity['desired']:
        print(f"  Scaling: {current_capacity['desired']} â†’ {required_workers}")
        set_desired_capacity(required_workers)
    else:
        print(f"  No scaling needed")

    # 5. ë©”íŠ¸ë¦­ ë°œí–‰
    publish_metrics(queue_depths, required_workers, current_capacity)

    return {
        'statusCode': 200,
        'body': {
            'queue_depths': queue_depths,
            'required_workers': required_workers,
            'current_capacity': current_capacity,
        }
    }
```

### 4.4 Lambda ë°°í¬ (Terraform)

```hcl
# terraform/lambda.tf

# Lambda Function: Auto Scaler
resource "aws_lambda_function" "auto_scaler" {
  filename      = "lambda_auto_scaler.zip"
  function_name = "invokeai-gpu-auto-scaler"
  role          = aws_iam_role.lambda_auto_scaler.arn
  handler       = "auto_scaler.lambda_handler"
  runtime       = "python3.11"
  timeout       = 60

  environment {
    variables = {
      ASG_NAME          = aws_autoscaling_group.gpu_workers.name
      HIGH_QUEUE_URL    = aws_sqs_queue.high_priority.url
      MEDIUM_QUEUE_URL  = aws_sqs_queue.medium_priority.url
      LOW_QUEUE_URL     = aws_sqs_queue.low_priority.url
    }
  }

  tags = {
    Name = "invokeai-gpu-auto-scaler"
  }
}

# CloudWatch Events Rule (1ë¶„ë§ˆë‹¤ ì‹¤í–‰)
resource "aws_cloudwatch_event_rule" "auto_scaler_schedule" {
  name                = "invokeai-auto-scaler-schedule"
  description         = "Trigger GPU auto scaler every minute"
  schedule_expression = "rate(1 minute)"
}

resource "aws_cloudwatch_event_target" "auto_scaler" {
  rule      = aws_cloudwatch_event_rule.auto_scaler_schedule.name
  target_id = "AutoScalerLambda"
  arn       = aws_lambda_function.auto_scaler.arn
}

resource "aws_lambda_permission" "allow_cloudwatch" {
  statement_id  = "AllowExecutionFromCloudWatch"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.auto_scaler.function_name
  principal     = "events.amazonaws.com"
  source_arn    = aws_cloudwatch_event_rule.auto_scaler_schedule.arn
}
```

---

## 5. Lambda ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜

### 5.1 ì‘ì—… ìƒíƒœ ê´€ë¦¬ (DynamoDB)

```hcl
# terraform/dynamodb.tf

# Tasks Table
resource "aws_dynamodb_table" "tasks" {
  name           = "invokeai-tasks"
  billing_mode   = "PAY_PER_REQUEST"  # On-demand (ë¹„ìš© íš¨ìœ¨ì )
  hash_key       = "task_id"
  range_key      = "user_id"

  attribute {
    name = "task_id"
    type = "S"
  }

  attribute {
    name = "user_id"
    type = "S"
  }

  attribute {
    name = "status"
    type = "S"
  }

  attribute {
    name = "created_at"
    type = "S"
  }

  # GSI: ì‚¬ìš©ìë³„ ì‘ì—… ì¡°íšŒ
  global_secondary_index {
    name            = "user-index"
    hash_key        = "user_id"
    range_key       = "created_at"
    projection_type = "ALL"
  }

  # GSI: ìƒíƒœë³„ ì‘ì—… ì¡°íšŒ
  global_secondary_index {
    name            = "status-index"
    hash_key        = "status"
    range_key       = "created_at"
    projection_type = "ALL"
  }

  # TTL ì„¤ì • (30ì¼ í›„ ìë™ ì‚­ì œ)
  ttl {
    attribute_name = "ttl"
    enabled        = true
  }

  tags = {
    Name = "invokeai-tasks"
  }
}
```

### 5.2 WebSocket API (ì‹¤ì‹œê°„ ìƒíƒœ ì•Œë¦¼)

```python
# lambda/websocket_handler.py
"""
WebSocket API Handler
- í´ë¼ì´ì–¸íŠ¸ ì—°ê²°/í•´ì œ ê´€ë¦¬
- ì‘ì—… ìƒíƒœ ë³€ê²½ ì‹œ ì‹¤ì‹œê°„ ì•Œë¦¼
"""

import boto3
import json
import os

dynamodb = boto3.resource('dynamodb')
connections_table = dynamodb.Table('invokeai-websocket-connections')


def connect_handler(event, context):
    """í´ë¼ì´ì–¸íŠ¸ ì—°ê²°"""
    connection_id = event['requestContext']['connectionId']
    user_id = event['queryStringParameters'].get('user_id')

    connections_table.put_item(
        Item={
            'connection_id': connection_id,
            'user_id': user_id,
        }
    )

    return {'statusCode': 200, 'body': 'Connected'}


def disconnect_handler(event, context):
    """í´ë¼ì´ì–¸íŠ¸ í•´ì œ"""
    connection_id = event['requestContext']['connectionId']

    connections_table.delete_item(
        Key={'connection_id': connection_id}
    )

    return {'statusCode': 200, 'body': 'Disconnected'}


def notify_task_update(task_id, user_id, status, data=None):
    """
    íŠ¹ì • ì‚¬ìš©ìì—ê²Œ ì‘ì—… ì—…ë°ì´íŠ¸ ì•Œë¦¼

    DynamoDB Streamì—ì„œ í˜¸ì¶œë¨
    """
    apigw = boto3.client('apigatewaymanagementapi',
                         endpoint_url=os.environ['WEBSOCKET_ENDPOINT'])

    # í•´ë‹¹ ì‚¬ìš©ìì˜ ëª¨ë“  ì—°ê²° ì¡°íšŒ
    response = connections_table.query(
        IndexName='user-index',
        KeyConditionExpression='user_id = :uid',
        ExpressionAttributeValues={':uid': user_id}
    )

    message = {
        'event': 'task_update',
        'task_id': task_id,
        'status': status,
        'data': data or {},
    }

    # ê° ì—°ê²°ì— ë©”ì‹œì§€ ì „ì†¡
    for item in response['Items']:
        try:
            apigw.post_to_connection(
                ConnectionId=item['connection_id'],
                Data=json.dumps(message).encode('utf-8')
            )
        except apigw.exceptions.GoneException:
            # ì—°ê²°ì´ ëŠê¸´ ê²½ìš° ì‚­ì œ
            connections_table.delete_item(
                Key={'connection_id': item['connection_id']}
            )
```

---

## 6. OOM ë°©ì§€ ì „ëµ

### 6.1 GPU ë©”ëª¨ë¦¬ ê´€ë¦¬

```python
# invokeai/app/services/gpu_memory_manager.py
"""
GPU ë©”ëª¨ë¦¬ ê´€ë¦¬
- ì‘ì—… ì „ ë©”ëª¨ë¦¬ ì²´í¬
- ëª¨ë¸ ì–¸ë¡œë“œ/ë¡œë“œ
- CUDA ìºì‹œ ì •ë¦¬
"""

import torch
import gc
from typing import Optional


class GPUMemoryManager:
    def __init__(self, max_memory_usage: float = 0.9):
        """
        Args:
            max_memory_usage: ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (0-1)
        """
        self.max_memory_usage = max_memory_usage
        self.current_model = None

    def get_memory_info(self) -> dict:
        """í˜„ì¬ GPU ë©”ëª¨ë¦¬ ì •ë³´"""
        if not torch.cuda.is_available():
            return {}

        total = torch.cuda.get_device_properties(0).total_memory
        reserved = torch.cuda.memory_reserved(0)
        allocated = torch.cuda.memory_allocated(0)

        return {
            'total_gb': total / 1024**3,
            'reserved_gb': reserved / 1024**3,
            'allocated_gb': allocated / 1024**3,
            'free_gb': (total - reserved) / 1024**3,
            'usage_percent': (reserved / total) * 100,
        }

    def check_memory_available(self, required_gb: float = 8.0) -> bool:
        """
        ì¶©ë¶„í•œ ë©”ëª¨ë¦¬ê°€ ìˆëŠ”ì§€ í™•ì¸

        Args:
            required_gb: í•„ìš”í•œ ë©”ëª¨ë¦¬ (GB)

        Returns:
            bool: ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
        """
        mem_info = self.get_memory_info()

        if not mem_info:
            return False

        return mem_info['free_gb'] >= required_gb

    def clear_memory(self):
        """GPU ë©”ëª¨ë¦¬ ì •ë¦¬"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()

        gc.collect()

    def unload_model(self):
        """í˜„ì¬ ëª¨ë¸ ì–¸ë¡œë“œ"""
        if self.current_model is not None:
            del self.current_model
            self.current_model = None
            self.clear_memory()

    def load_model(self, model_name: str, model_loader_fn):
        """
        ëª¨ë¸ ë¡œë“œ (ë©”ëª¨ë¦¬ ì²´í¬ í¬í•¨)

        Args:
            model_name: ëª¨ë¸ ì´ë¦„
            model_loader_fn: ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
        """
        # í˜„ì¬ ëª¨ë¸ê³¼ ë‹¤ë¥´ë©´ ì–¸ë¡œë“œ
        if self.current_model is not None and self.current_model != model_name:
            self.unload_model()

        # ë©”ëª¨ë¦¬ ì²´í¬
        if not self.check_memory_available():
            self.clear_memory()

            if not self.check_memory_available():
                raise MemoryError("Insufficient GPU memory")

        # ëª¨ë¸ ë¡œë“œ
        if self.current_model is None:
            self.current_model = model_loader_fn(model_name)

        return self.current_model

    def monitor_memory_during_generation(self):
        """ìƒì„± ì¤‘ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ (ë°ì½”ë ˆì´í„°)"""
        def decorator(func):
            def wrapper(*args, **kwargs):
                # ì‹œì‘ ì „ ë©”ëª¨ë¦¬
                mem_before = self.get_memory_info()
                print(f"Memory before: {mem_before['allocated_gb']:.2f} GB")

                try:
                    result = func(*args, **kwargs)

                    # ì™„ë£Œ í›„ ë©”ëª¨ë¦¬
                    mem_after = self.get_memory_info()
                    print(f"Memory after: {mem_after['allocated_gb']:.2f} GB")

                    # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìœ¼ë©´ ì •ë¦¬
                    if mem_after['usage_percent'] > self.max_memory_usage * 100:
                        self.clear_memory()

                    return result

                except RuntimeError as e:
                    if "out of memory" in str(e).lower():
                        print("CUDA OOM detected! Clearing memory...")
                        self.clear_memory()
                        raise MemoryError("GPU out of memory")
                    raise

            return wrapper
        return decorator
```

### 6.2 Workerì— ë©”ëª¨ë¦¬ ê´€ë¦¬ í†µí•©

```python
# worker.py ìˆ˜ì •
from invokeai.app.services.gpu_memory_manager import GPUMemoryManager

# ì „ì—­ ë©”ëª¨ë¦¬ ë§¤ë‹ˆì €
memory_manager = GPUMemoryManager(max_memory_usage=0.85)


def process_task(message, queue_url):
    """ì‘ì—… ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ê´€ë¦¬ í¬í•¨)"""
    global last_activity
    last_activity = time.time()

    body = json.loads(message['Body'])
    task_id = body['task_id']
    user_id = body['user_id']
    task_data = body['data']

    try:
        # ë©”ëª¨ë¦¬ ì²´í¬
        mem_info = memory_manager.get_memory_info()
        print(f"GPU Memory: {mem_info['allocated_gb']:.2f}/{mem_info['total_gb']:.2f} GB")

        if not memory_manager.check_memory_available(required_gb=8.0):
            raise MemoryError("Insufficient GPU memory")

        # ìƒíƒœ ì—…ë°ì´íŠ¸: processing
        update_task_status(task_id, user_id, 'processing')

        # ì´ë¯¸ì§€ ìƒì„± (ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§)
        @memory_manager.monitor_memory_during_generation()
        def generate():
            return generate_image(
                prompt=task_data['prompt'],
                negative_prompt=task_data.get('negative_prompt', ''),
                width=task_data['width'],
                height=task_data['height'],
                steps=task_data['steps'],
            )

        image_bytes = generate()

        # S3 ì—…ë¡œë“œ
        s3_key = f"images/{user_id}/{task_id}.png"
        upload_to_s3(s3_key, image_bytes)

        image_url = f"https://{S3_BUCKET}.s3.amazonaws.com/{s3_key}"

        # ìƒíƒœ ì—…ë°ì´íŠ¸: completed
        update_task_status(task_id, user_id, 'completed', image_url=image_url)

        # SQS ë©”ì‹œì§€ ì‚­ì œ
        delete_message(queue_url, message['ReceiptHandle'])

        print(f"Task {task_id} completed successfully")

    except MemoryError as e:
        print(f"Memory error: {str(e)}")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        memory_manager.clear_memory()

        # ìƒíƒœ ì—…ë°ì´íŠ¸: failed
        update_task_status(task_id, user_id, 'failed', error="GPU out of memory")

    except Exception as e:
        print(f"Error: {str(e)}")
        update_task_status(task_id, user_id, 'failed', error=str(e))
```

### 6.3 Circuit Breaker íŒ¨í„´

```python
# invokeai/app/services/circuit_breaker.py
"""
Circuit Breaker íŒ¨í„´
- ì—°ì† ì‹¤íŒ¨ ì‹œ ì¼ì‹œì ìœ¼ë¡œ ì‘ì—… ì¤‘ë‹¨
- OOM ë°œìƒë¥  ê°ì†Œ
"""

from enum import Enum
from datetime import datetime, timedelta


class CircuitState(Enum):
    CLOSED = "closed"      # ì •ìƒ
    OPEN = "open"          # ì°¨ë‹¨ (ì‹¤íŒ¨ ë§ìŒ)
    HALF_OPEN = "half_open"  # ë³µêµ¬ ì‹œë„


class CircuitBreaker:
    def __init__(
        self,
        failure_threshold: int = 5,
        timeout: int = 60,
        success_threshold: int = 2
    ):
        """
        Args:
            failure_threshold: ì°¨ë‹¨ ì„ê³„ê°’
            timeout: ì°¨ë‹¨ ì‹œê°„ (ì´ˆ)
            success_threshold: ë³µêµ¬ ì„ê³„ê°’
        """
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.success_threshold = success_threshold

        self.state = CircuitState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time = None

    def call(self, func, *args, **kwargs):
        """í•¨ìˆ˜ í˜¸ì¶œ (Circuit Breaker ì ìš©)"""
        if self.state == CircuitState.OPEN:
            # ì°¨ë‹¨ ìƒíƒœ
            if datetime.now() - self.last_failure_time > timedelta(seconds=self.timeout):
                # íƒ€ì„ì•„ì›ƒ ê²½ê³¼ â†’ HALF_OPENìœ¼ë¡œ ì „í™˜
                self.state = CircuitState.HALF_OPEN
                self.success_count = 0
            else:
                raise Exception("Circuit breaker is OPEN")

        try:
            result = func(*args, **kwargs)
            self._on_success()
            return result

        except Exception as e:
            self._on_failure()
            raise e

    def _on_success(self):
        """ì„±ê³µ ì²˜ë¦¬"""
        self.failure_count = 0

        if self.state == CircuitState.HALF_OPEN:
            self.success_count += 1

            if self.success_count >= self.success_threshold:
                # ë³µêµ¬ ì„±ê³µ â†’ CLOSEDë¡œ ì „í™˜
                self.state = CircuitState.CLOSED
                self.success_count = 0

    def _on_failure(self):
        """ì‹¤íŒ¨ ì²˜ë¦¬"""
        self.failure_count += 1
        self.last_failure_time = datetime.now()

        if self.failure_count >= self.failure_threshold:
            # ì‹¤íŒ¨ ì„ê³„ê°’ ì´ˆê³¼ â†’ OPENìœ¼ë¡œ ì „í™˜
            self.state = CircuitState.OPEN


# ì „ì—­ Circuit Breaker
gpu_circuit_breaker = CircuitBreaker(
    failure_threshold=5,  # 5ë²ˆ ì—°ì† ì‹¤íŒ¨ ì‹œ ì°¨ë‹¨
    timeout=60,           # 1ë¶„ í›„ ì¬ì‹œë„
    success_threshold=2   # 2ë²ˆ ì„±ê³µ ì‹œ ë³µêµ¬
)
```

---

## 7. ëª¨ë‹ˆí„°ë§ ë° ì•ŒëŒ

### 7.1 CloudWatch ëŒ€ì‹œë³´ë“œ

```hcl
# terraform/cloudwatch.tf

resource "aws_cloudwatch_dashboard" "main" {
  dashboard_name = "InvokeAI-Production"

  dashboard_body = jsonencode({
    widgets = [
      # SQS Queue Depth
      {
        type = "metric"
        properties = {
          metrics = [
            ["AWS/SQS", "ApproximateNumberOfMessagesVisible", { stat = "Average", label = "High Priority" }, { queue = aws_sqs_queue.high_priority.name }],
            ["...", { stat = "Average", label = "Medium Priority" }, { queue = aws_sqs_queue.medium_priority.name }],
            ["...", { stat = "Average", label = "Low Priority" }, { queue = aws_sqs_queue.low_priority.name }],
          ]
          period = 60
          stat   = "Average"
          region = "us-east-1"
          title  = "Queue Depth"
        }
      },

      # GPU Workers
      {
        type = "metric"
        properties = {
          metrics = [
            ["InvokeAI/Workers", "CurrentWorkers", { stat = "Average", label = "Current" }],
            ["...", "RequiredWorkers", { stat = "Average", label = "Required" }],
          ]
          period = 60
          stat   = "Average"
          region = "us-east-1"
          title  = "GPU Workers"
        }
      },

      # Task Success Rate
      {
        type = "metric"
        properties = {
          metrics = [
            ["InvokeAI/Tasks", "Completed", { stat = "Sum", label = "Completed" }],
            ["...", "Failed", { stat = "Sum", label = "Failed" }],
          ]
          period = 300
          stat   = "Sum"
          region = "us-east-1"
          title  = "Task Success Rate"
        }
      },

      # GPU Memory Usage
      {
        type = "metric"
        properties = {
          metrics = [
            ["InvokeAI/GPU", "MemoryUsagePercent", { stat = "Average" }],
          ]
          period = 60
          stat   = "Average"
          region = "us-east-1"
          title  = "GPU Memory Usage"
          yAxis  = { left = { min = 0, max = 100 } }
        }
      },

      # Cost Estimation
      {
        type = "metric"
        properties = {
          metrics = [
            ["InvokeAI/Cost", "EstimatedHourlyCost", { stat = "Average" }],
          ]
          period = 3600
          stat   = "Average"
          region = "us-east-1"
          title  = "Estimated Hourly Cost ($)"
        }
      },
    ]
  })
}
```

### 7.2 CloudWatch Alarms

```hcl
# terraform/alarms.tf

# Alarm: DLQì— ë©”ì‹œì§€ê°€ ìŒ“ì„
resource "aws_cloudwatch_metric_alarm" "dlq_messages" {
  alarm_name          = "invokeai-dlq-messages"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 1
  metric_name         = "ApproximateNumberOfMessagesVisible"
  namespace           = "AWS/SQS"
  period              = 300
  statistic           = "Average"
  threshold           = 10
  alarm_description   = "DLQ has more than 10 messages"

  dimensions = {
    QueueName = aws_sqs_queue.dlq.name
  }

  alarm_actions = [aws_sns_topic.critical_alerts.arn]
}

# Alarm: High Queue Age (ì‘ì—… ëŒ€ê¸° ì‹œê°„ ë„ˆë¬´ ê¹€)
resource "aws_cloudwatch_metric_alarm" "high_queue_age" {
  alarm_name          = "invokeai-high-queue-age"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "ApproximateAgeOfOldestMessage"
  namespace           = "AWS/SQS"
  period              = 300
  statistic           = "Maximum"
  threshold           = 1800  # 30ë¶„
  alarm_description   = "Messages waiting more than 30 minutes"

  dimensions = {
    QueueName = aws_sqs_queue.medium_priority.name
  }

  alarm_actions = [aws_sns_topic.scaling_alerts.arn]
}

# Alarm: No GPU Workers (ì‘ì—…ì€ ìˆëŠ”ë° ì›Œì»¤ê°€ ì—†ìŒ)
resource "aws_cloudwatch_metric_alarm" "no_workers_with_queue" {
  alarm_name          = "invokeai-no-workers-with-queue"
  comparison_operator = "LessThanThreshold"
  evaluation_periods  = 2
  metric_name         = "CurrentWorkers"
  namespace           = "InvokeAI/Workers"
  period              = 300
  statistic           = "Average"
  threshold           = 1
  alarm_description   = "No workers running but queue has messages"

  # ì¶”ê°€ ì¡°ê±´: Queue depth > 0
  # (Terraformì—ì„œëŠ” ë³µí•© ì¡°ê±´ì„ ì§ì ‘ ì§€ì› ì•ˆ í•¨, CloudWatch Insights ì‚¬ìš©)

  alarm_actions = [aws_sns_topic.critical_alerts.arn]
}

# Alarm: High GPU Memory Usage
resource "aws_cloudwatch_metric_alarm" "high_gpu_memory" {
  alarm_name          = "invokeai-high-gpu-memory"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "MemoryUsagePercent"
  namespace           = "InvokeAI/GPU"
  period              = 60
  statistic           = "Average"
  threshold           = 90
  alarm_description   = "GPU memory usage over 90%"

  alarm_actions = [aws_sns_topic.scaling_alerts.arn]
}

# SNS Topics
resource "aws_sns_topic" "critical_alerts" {
  name = "invokeai-critical-alerts"
}

resource "aws_sns_topic" "scaling_alerts" {
  name = "invokeai-scaling-alerts"
}

# Email Subscriptions
resource "aws_sns_topic_subscription" "critical_email" {
  topic_arn = aws_sns_topic.critical_alerts.arn
  protocol  = "email"
  endpoint  = "devops@yourdomain.com"
}
```

### 7.3 GPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (Workerì—ì„œ)

```python
# worker.py - CloudWatch ë©”íŠ¸ë¦­ ë°œí–‰
import boto3

cloudwatch = boto3.client('cloudwatch', region_name=os.environ['AWS_REGION'])


def publish_gpu_metrics(memory_info):
    """GPU ë©”íŠ¸ë¦­ ë°œí–‰"""
    cloudwatch.put_metric_data(
        Namespace='InvokeAI/GPU',
        MetricData=[
            {
                'MetricName': 'MemoryUsagePercent',
                'Value': memory_info['usage_percent'],
                'Unit': 'Percent',
                'Timestamp': datetime.utcnow(),
            },
            {
                'MetricName': 'MemoryAllocatedGB',
                'Value': memory_info['allocated_gb'],
                'Unit': 'Gigabytes',
                'Timestamp': datetime.utcnow(),
            },
        ]
    )


def publish_task_metrics(status):
    """ì‘ì—… ë©”íŠ¸ë¦­ ë°œí–‰"""
    cloudwatch.put_metric_data(
        Namespace='InvokeAI/Tasks',
        MetricData=[
            {
                'MetricName': status.capitalize(),  # Completed or Failed
                'Value': 1,
                'Unit': 'Count',
                'Timestamp': datetime.utcnow(),
            }
        ]
    )


# process_task() í•¨ìˆ˜ì— ì¶”ê°€
def process_task(message, queue_url):
    # ... (ê¸°ì¡´ ì½”ë“œ)

    try:
        # GPU ë©”ëª¨ë¦¬ ì²´í¬
        mem_info = memory_manager.get_memory_info()
        publish_gpu_metrics(mem_info)

        # ì´ë¯¸ì§€ ìƒì„±
        # ...

        # ì„±ê³µ ë©”íŠ¸ë¦­
        publish_task_metrics('completed')

    except Exception as e:
        # ì‹¤íŒ¨ ë©”íŠ¸ë¦­
        publish_task_metrics('failed')
```

---

## 8. ë¹„ìš© ë¶„ì„

### 8.1 ì‹œê°„ëŒ€ë³„ ë¹„ìš© ì¶”ì •

```python
# Cost Analysis Spreadsheet

# ê°€ì •:
# - g5.xlarge Spot: $0.50/hour (On-Demand $1.00ì˜ 50%)
# - SQS: $0.40 / 1M requests
# - DynamoDB: $1.25 / 1M write requests
# - S3: $0.023 / GB
# - Data Transfer: $0.09 / GB

# ì‹œë‚˜ë¦¬ì˜¤ 1: ìœ íœ´ ì‹œê°„ (ì•¼ê°„/ì£¼ë§)
idle_cost_per_hour = {
    "GPU Workers": 0,  # 0ê°œ ì‹¤í–‰
    "SQS": 0.001,      # ìµœì†Œ í´ë§
    "DynamoDB": 0,
    "S3": 0.01,        # ê¸°ì¡´ ì €ì¥
    "Total": 0.011,    # ~$0.01/hour = $7.92/month (ìœ íœ´ ì‹œ)
}

# ì‹œë‚˜ë¦¬ì˜¤ 2: í”¼í¬ ì‹œê°„ (ë™ì ‘ 100ëª…, 1ì‹œê°„)
peak_cost_per_hour = {
    "GPU Workers": 5.0,    # 10ê°œ Ã— $0.50 (í‰ê·  í™œìš© 50%)
    "SQS": 0.004,          # 1000 ì‘ì—… Ã— $0.0000004
    "DynamoDB": 0.00125,   # 1000 writes Ã— $0.00000125
    "S3 Storage": 0.023,   # 1GB ìƒì„±
    "S3 Transfer": 0.09,   # 1GB ë‹¤ìš´ë¡œë“œ
    "Total": 5.12,         # ~$5/hour (í”¼í¬ ì‹œ)
}

# ì›”ê°„ ë¹„ìš© (í‰ê·  í™œìš©ë¥  20%)
monthly_cost = {
    "Idle (18h/day Ã— 30 days)": 0.011 * 18 * 30,    # $5.94
    "Peak (6h/day Ã— 30 days)": 5.12 * 6 * 30,       # $921.60
    "Total": 927.54,                                 # ~$928/month
}

# ê¸°ì¡´ Redis + Celery ë°©ì‹ (ì°¸ê³ )
baseline_cost_monthly = {
    "ElastiCache Redis (cache.r6g.large)": 130,
    "GPU Workers (24ì‹œê°„, ìµœì†Œ 2ê°œ)": 720,  # 2 Ã— $0.50 Ã— 720h
    "Total": 850,  # $850/month (ìµœì†Œ)
}

# ì ˆê°ì•¡: $850 - $928 = -$78 (ë” ë¹„ìŒˆ?)
# â†’ í•˜ì§€ë§Œ íŠ¸ë˜í”½ ë³€ë™ì´ í° ê²½ìš° ìƒˆ ë°©ì‹ì´ ìœ ë¦¬
# â†’ ì˜ˆ: ì•¼ê°„/ì£¼ë§ íŠ¸ë˜í”½ 0 â†’ ê¸°ì¡´ $850, ìƒˆ ë°©ì‹ $6
```

### 8.2 ë¹„ìš© ìµœì í™” íŒ

1. **Reserved Instances ì‚¬ìš© ê¸ˆì§€** (Spotìœ¼ë¡œ ì¶©ë¶„)
2. **Savings Plans** (1ë…„ ì•½ì • ì‹œ 30% ì¶”ê°€ í• ì¸)
3. **S3 Intelligent-Tiering** (90ì¼ í›„ ìë™ Glacier)
4. **DynamoDB On-Demand** (íŠ¸ë˜í”½ ì˜ˆì¸¡ ì–´ë ¤ìš¸ ë•Œ)
5. **CloudWatch Logs ë³´ì¡´ ê¸°ê°„ ë‹¨ì¶•** (7ì¼ â†’ 3ì¼)

### 8.3 ì‹¤ì‹œê°„ ë¹„ìš© ì¶”ì 

```python
# lambda/cost_tracker.py
"""
ì‹¤ì‹œê°„ ë¹„ìš© ì¶”ì 
- ë§¤ ì‹œê°„ ë¹„ìš© ì¶”ì •
- CloudWatch ë©”íŠ¸ë¦­ ë°œí–‰
"""

import boto3
from datetime import datetime, timedelta

cloudwatch = boto3.client('cloudwatch')
ec2 = boto3.client('ec2')
autoscaling = boto3.client('autoscaling')


def estimate_hourly_cost():
    """í˜„ì¬ ì‹œê°„ë‹¹ ë¹„ìš© ì¶”ì •"""

    # GPU ì›Œì»¤ ìˆ˜
    asg = autoscaling.describe_auto_scaling_groups(
        AutoScalingGroupNames=['invokeai-gpu-workers']
    )['AutoScalingGroups'][0]

    num_workers = len(asg['Instances'])

    # g5.xlarge Spot í‰ê·  ê°€ê²©: $0.50
    gpu_cost = num_workers * 0.50

    # SQS (ë§¤ìš° ì €ë ´, ë¬´ì‹œ ê°€ëŠ¥)
    sqs_cost = 0.001

    # ì´ ë¹„ìš©
    total_cost = gpu_cost + sqs_cost

    # CloudWatch ë©”íŠ¸ë¦­ ë°œí–‰
    cloudwatch.put_metric_data(
        Namespace='InvokeAI/Cost',
        MetricData=[
            {
                'MetricName': 'EstimatedHourlyCost',
                'Value': total_cost,
                'Unit': 'None',
                'Timestamp': datetime.utcnow(),
            }
        ]
    )

    return total_cost


def lambda_handler(event, context):
    cost = estimate_hourly_cost()
    print(f"Estimated hourly cost: ${cost:.2f}")

    return {'statusCode': 200, 'body': f"${cost:.2f}"}
```

---

## 9. ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ

### 9.1 ì‚¬ì „ ì¤€ë¹„ (Week 1)

**1. AWS ê³„ì • ë° ê¶Œí•œ ì„¤ì •**

```bash
# AWS CLI ì„¤ì¹˜ í™•ì¸
aws --version

# ê³„ì • ì„¤ì •
aws configure
# Access Key ID: YOUR_ACCESS_KEY
# Secret Access Key: YOUR_SECRET_KEY
# Region: us-east-1
# Output format: json

# Terraform ì„¤ì¹˜
brew install terraform
terraform --version
```

**2. í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±**

```bash
mkdir -p invokeai-saas/{terraform,lambda,scripts}
cd invokeai-saas

# Terraform ì´ˆê¸°í™”
cd terraform
terraform init
```

**3. S3 ë²„í‚· ìƒì„± (Terraform State ì €ì¥)**

```hcl
# terraform/backend.tf
terraform {
  backend "s3" {
    bucket = "invokeai-terraform-state"
    key    = "production/terraform.tfstate"
    region = "us-east-1"
    encrypt = true
  }
}
```

### 9.2 ì¸í”„ë¼ êµ¬ì¶• (Week 2-3)

**Step 1: VPC ìƒì„±**

```bash
cd terraform
terraform apply -target=module.vpc
```

**Step 2: SQS í ìƒì„±**

```bash
terraform apply -target=aws_sqs_queue.high_priority
terraform apply -target=aws_sqs_queue.medium_priority
terraform apply -target=aws_sqs_queue.low_priority
terraform apply -target=aws_sqs_queue.dlq
```

**Step 3: DynamoDB í…Œì´ë¸” ìƒì„±**

```bash
terraform apply -target=aws_dynamodb_table.tasks
```

**Step 4: S3 ë²„í‚· ìƒì„± (ì´ë¯¸ì§€ ì €ì¥)**

```bash
terraform apply -target=aws_s3_bucket.images
```

**Step 5: IAM ì—­í•  ìƒì„±**

```bash
terraform apply -target=aws_iam_role.gpu_worker
terraform apply -target=aws_iam_role.lambda_auto_scaler
```

**Step 6: Launch Template & ASG ìƒì„±**

```bash
terraform apply -target=aws_launch_template.gpu_worker
terraform apply -target=aws_autoscaling_group.gpu_workers
```

### 9.3 ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ìˆ˜ì • (Week 3-4)

**Step 1: FastAPIì— SQS í†µí•©**

```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
pip install boto3

# ì½”ë“œ ìˆ˜ì •
# - invokeai/app/services/queue_service.py
# - invokeai/app/api/routers/images.py
```

**Step 2: GPU Worker ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±**

```bash
# worker.py ì‘ì„±
# - SQS í´ë§ ë¡œì§
# - ì´ë¯¸ì§€ ìƒì„± ë¡œì§
# - S3 ì—…ë¡œë“œ ë¡œì§
# - DynamoDB ì—…ë°ì´íŠ¸ ë¡œì§
```

**Step 3: Lambda Functions ë°°í¬**

```bash
# Lambda íŒ¨í‚¤ì§€ ìƒì„±
cd lambda
pip install -r requirements.txt -t .
zip -r auto_scaler.zip .

# Terraformìœ¼ë¡œ ë°°í¬
cd ../terraform
terraform apply -target=aws_lambda_function.auto_scaler
terraform apply -target=aws_cloudwatch_event_rule.auto_scaler_schedule
```

### 9.4 AMI ìƒì„± (Week 4)

**Step 1: ë² ì´ìŠ¤ EC2 ì¸ìŠ¤í„´ìŠ¤ ì‹¤í–‰**

```bash
# Deep Learning AMI ì‚¬ìš©
aws ec2 run-instances \
  --image-id ami-0abcdef1234567890 \
  --instance-type g5.xlarge \
  --key-name your-key-pair \
  --security-group-ids sg-xxxxx \
  --subnet-id subnet-xxxxx
```

**Step 2: ì¸ìŠ¤í„´ìŠ¤ ì„¤ì •**

```bash
# SSH ì ‘ì†
ssh -i your-key.pem ubuntu@<instance-ip>

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
sudo apt-get update
sudo apt-get install -y python3-pip git

# InvokeAI ì„¤ì¹˜
cd /opt
sudo git clone https://github.com/invoke-ai/InvokeAI.git
cd InvokeAI
sudo python3 -m venv venv
sudo venv/bin/pip install -r requirements.txt

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
aws s3 sync s3://invokeai-models/models /opt/InvokeAI/models

# Worker ìŠ¤í¬ë¦½íŠ¸ ë³µì‚¬
sudo cp /path/to/worker.py /opt/InvokeAI/

# Systemd ì„œë¹„ìŠ¤ ìƒì„±
sudo cp /path/to/invokeai-worker.service /etc/systemd/system/
```

**Step 3: AMI ìƒì„±**

```bash
# ì¸ìŠ¤í„´ìŠ¤ ID í™•ì¸
INSTANCE_ID=$(aws ec2 describe-instances \
  --filters "Name=tag:Name,Values=invokeai-worker-base" \
  --query "Reservations[0].Instances[0].InstanceId" \
  --output text)

# AMI ìƒì„±
aws ec2 create-image \
  --instance-id $INSTANCE_ID \
  --name "invokeai-gpu-worker-v1" \
  --description "InvokeAI GPU Worker with models" \
  --no-reboot

# AMI ID í™•ì¸
AMI_ID=$(aws ec2 describe-images \
  --owners self \
  --filters "Name=name,Values=invokeai-gpu-worker-v1" \
  --query "Images[0].ImageId" \
  --output text)

echo "AMI created: $AMI_ID"

# Launch Templateì— AMI ID ì—…ë°ì´íŠ¸
# terraform/gpu_worker.tfì—ì„œ image_id ìˆ˜ì • í›„ ì¬ë°°í¬
```

### 9.5 ëª¨ë‹ˆí„°ë§ ì„¤ì • (Week 5)

**Step 1: CloudWatch Dashboard ìƒì„±**

```bash
terraform apply -target=aws_cloudwatch_dashboard.main
```

**Step 2: Alarms ì„¤ì •**

```bash
terraform apply -target=aws_cloudwatch_metric_alarm.dlq_messages
terraform apply -target=aws_cloudwatch_metric_alarm.high_queue_age
terraform apply -target=aws_cloudwatch_metric_alarm.high_gpu_memory
```

**Step 3: SNS Email êµ¬ë… í™•ì¸**

```bash
# ì´ë©”ì¼ë¡œ ì „ì†¡ëœ êµ¬ë… í™•ì¸ ë§í¬ í´ë¦­
```

---

## 10. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

### 10.1 ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

**Test 1: ë‹¨ì¼ ì‘ì—… í…ŒìŠ¤íŠ¸**

```bash
# API í˜¸ì¶œ
curl -X POST https://api.invokeai.com/api/v1/images/generate \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "A beautiful sunset over mountains",
    "width": 1024,
    "height": 1024,
    "steps": 30
  }'

# ì‘ë‹µ:
# {
#   "task_id": "abc-123-def-456",
#   "status": "queued",
#   "estimated_wait_time_seconds": 45
# }

# ì‘ì—… ìƒíƒœ ì¡°íšŒ (ëª‡ ì´ˆ í›„)
curl https://api.invokeai.com/api/v1/images/tasks/abc-123-def-456 \
  -H "Authorization: Bearer YOUR_TOKEN"

# ì‘ë‹µ:
# {
#   "task_id": "abc-123-def-456",
#   "status": "completed",
#   "image_url": "https://invokeai-images.s3.amazonaws.com/images/user123/abc-123-def-456.png"
# }
```

**Test 2: Auto Scaling í…ŒìŠ¤íŠ¸**

```python
# test_auto_scaling.py
"""
100ê°œ ì‘ì—…ì„ ë™ì‹œì— ì „ì†¡í•˜ì—¬ Auto Scaling í…ŒìŠ¤íŠ¸
"""

import requests
import concurrent.futures
import time


API_ENDPOINT = "https://api.invokeai.com/api/v1/images/generate"
TOKEN = "YOUR_TOKEN"


def create_task(i):
    """ë‹¨ì¼ ì‘ì—… ìƒì„±"""
    response = requests.post(
        API_ENDPOINT,
        headers={"Authorization": f"Bearer {TOKEN}"},
        json={
            "prompt": f"Test image {i}",
            "width": 1024,
            "height": 1024,
            "steps": 30,
        }
    )
    return response.json()


def main():
    print("Creating 100 tasks...")

    start_time = time.time()

    # 100ê°œ ì‘ì—… ë™ì‹œ ìƒì„±
    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
        futures = [executor.submit(create_task, i) for i in range(100)]
        results = [f.result() for f in concurrent.futures.as_completed(futures)]

    print(f"Created {len(results)} tasks in {time.time() - start_time:.2f}s")

    # CloudWatchì—ì„œ í™•ì¸:
    # - SQS Queue Depth: ~100
    # - Auto Scaler Lambda: ì‹¤í–‰ë¨
    # - ASG Desired Capacity: 0 â†’ 8-10
    # - GPU ì¸ìŠ¤í„´ìŠ¤: ì‹¤í–‰ ì¤‘


if __name__ == "__main__":
    main()
```

**Test 3: OOM ë°©ì§€ í…ŒìŠ¤íŠ¸**

```python
# test_oom_prevention.py
"""
ë§¤ìš° í° í•´ìƒë„ ì‘ì—…ì„ ì—°ì†ìœ¼ë¡œ ì „ì†¡í•˜ì—¬ OOM ë°©ì§€ í™•ì¸
"""

def create_large_task(i):
    """ëŒ€ìš©ëŸ‰ ì‘ì—… ìƒì„±"""
    response = requests.post(
        API_ENDPOINT,
        headers={"Authorization": f"Bearer {TOKEN}"},
        json={
            "prompt": f"Very detailed image {i}",
            "width": 2048,  # í° í•´ìƒë„
            "height": 2048,
            "steps": 50,     # ë§ì€ ìŠ¤í…
        }
    )
    return response.json()


# 10ê°œ ëŒ€ìš©ëŸ‰ ì‘ì—… ìƒì„±
for i in range(10):
    result = create_large_task(i)
    print(f"Task {i}: {result['task_id']}")

# í™•ì¸:
# - Worker ë¡œê·¸ì— GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì¶œë ¥
# - OOM ë°œìƒ ì‹œ ìë™ ì •ë¦¬ ë° ì¬ì‹œë„
# - Circuit Breakerê°€ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
```

### 10.2 ë¶€í•˜ í…ŒìŠ¤íŠ¸

```python
# test_load.py
"""
ì ì§„ì  ë¶€í•˜ ì¦ê°€ í…ŒìŠ¤íŠ¸
"""

import locust


class ImageGenerationUser(locust.HttpUser):
    wait_time = locust.between(5, 15)  # 5-15ì´ˆ ëŒ€ê¸°

    @locust.task
    def generate_image(self):
        """ì´ë¯¸ì§€ ìƒì„± ìš”ì²­"""
        self.client.post(
            "/api/v1/images/generate",
            headers={"Authorization": f"Bearer {self.token}"},
            json={
                "prompt": "Beautiful landscape",
                "width": 1024,
                "height": 1024,
                "steps": 30,
            }
        )


# ì‹¤í–‰:
# locust -f test_load.py --host https://api.invokeai.com

# ì‹œë‚˜ë¦¬ì˜¤:
# - 0-5ë¶„: 10 users
# - 5-10ë¶„: 50 users
# - 10-15ë¶„: 100 users
# - 15-20ë¶„: 150 users (ê³¼ë¶€í•˜ í…ŒìŠ¤íŠ¸)

# í™•ì¸:
# - Response time
# - Success rate
# - GPU ì›Œì»¤ ìˆ˜ ìë™ ì¦ê°€
# - Queue depth ë³€í™”
```

### 10.3 ë¹„ìš© ê²€ì¦

```bash
# 24ì‹œê°„ ìš´ì˜ í›„ ë¹„ìš© í™•ì¸

# AWS Cost Explorerì—ì„œ í™•ì¸
aws ce get-cost-and-usage \
  --time-period Start=2025-11-18,End=2025-11-19 \
  --granularity DAILY \
  --metrics "UnblendedCost" \
  --group-by Type=SERVICE

# ì˜ˆìƒ ê²°ê³¼:
# {
#   "ResultsByTime": [{
#     "Groups": [
#       {"Keys": ["Amazon Elastic Compute Cloud"], "Metrics": {"UnblendedCost": {"Amount": "12.50"}}},
#       {"Keys": ["Amazon Simple Queue Service"], "Metrics": {"UnblendedCost": {"Amount": "0.02"}}},
#       {"Keys": ["Amazon DynamoDB"], "Metrics": {"UnblendedCost": {"Amount": "0.15"}}},
#       {"Keys": ["Amazon Simple Storage Service"], "Metrics": {"UnblendedCost": {"Amount": "1.20"}}}
#     ]
#   }]
# }

# ì´ ë¹„ìš©: ~$14/day = $420/month (ë™ì ‘ 100ëª… ê¸°ì¤€)
```

---

## 11. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 11.1 ì›Œì»¤ê°€ ì‹œì‘ë˜ì§€ ì•ŠìŒ

**ì¦ìƒ:**
- SQSì— ë©”ì‹œì§€ê°€ ìŒ“ì„
- ASG Desired CapacityëŠ” ì¦ê°€í–ˆì§€ë§Œ ì¸ìŠ¤í„´ìŠ¤ê°€ ì•ˆ ëœ¸

**í•´ê²°:**

```bash
# 1. Spot ì¸ìŠ¤í„´ìŠ¤ ê°€ìš©ì„± í™•ì¸
aws ec2 describe-spot-price-history \
  --instance-types g5.xlarge \
  --start-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --product-descriptions "Linux/UNIX" \
  --query "SpotPriceHistory[*].[AvailabilityZone,SpotPrice]"

# 2. ASG ì´ë²¤íŠ¸ í™•ì¸
aws autoscaling describe-scaling-activities \
  --auto-scaling-group-name invokeai-gpu-workers \
  --max-records 10

# 3. Spot ê°€ê²©ì„ ë†’ì´ê±°ë‚˜ On-Demandë¡œ ì „í™˜
# terraform/gpu_worker.tfì—ì„œ max_price ì¦ê°€
```

### 11.2 OOM ê³„ì† ë°œìƒ

**ì¦ìƒ:**
- Worker ë¡œê·¸ì— "CUDA out of memory" ë°˜ë³µ
- ì‘ì—…ì´ ê³„ì† ì‹¤íŒ¨

**í•´ê²°:**

```python
# invokeai/app/services/gpu_memory_manager.py ìˆ˜ì •

# ë” ê³µê²©ì ì¸ ë©”ëª¨ë¦¬ ì •ë¦¬
def clear_memory(self):
    """GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (ê°•í™”)"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()
        torch.cuda.synchronize()  # ì¶”ê°€

    gc.collect()

    # íŒŒì´ì¬ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ë„ ê°•ì œ ì‹¤í–‰
    import gc
    gc.collect(generation=2)

# ë˜ëŠ” ì‘ì—…ë‹¹ ë©”ëª¨ë¦¬ ì œí•œ ê°•í™”
REQUIRED_MEMORY_GB = 10.0  # 8 â†’ 10ìœ¼ë¡œ ì¦ê°€
```

### 11.3 Lambda Auto Scalerê°€ ì‘ë™ ì•ˆ í•¨

**ì¦ìƒ:**
- CloudWatch Logsì— Lambda ì‹¤í–‰ ê¸°ë¡ ì—†ìŒ
- íì— ë©”ì‹œì§€ ìŒ“ì—¬ë„ ì›Œì»¤ ìˆ˜ ê·¸ëŒ€ë¡œ

**í•´ê²°:**

```bash
# 1. CloudWatch Events Rule í™•ì¸
aws events list-rules --name-prefix invokeai-auto-scaler

# 2. Lambda ê¶Œí•œ í™•ì¸
aws lambda get-policy --function-name invokeai-gpu-auto-scaler

# 3. ìˆ˜ë™ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
aws lambda invoke \
  --function-name invokeai-gpu-auto-scaler \
  --payload '{}' \
  response.json

cat response.json
```

---

## 12. ìš”ì•½

### 12.1 ì•„í‚¤í…ì²˜ ìš”ì•½

âœ… **ë©”ì‹œì§€ í**: Redis â†’ Amazon SQS (3ê°œ í)
âœ… **GPU ì›Œì»¤**: 24ì‹œê°„ ì‹¤í–‰ â†’ í•„ìš” ì‹œì—ë§Œ (0-10ê°œ)
âœ… **ìŠ¤ì¼€ì¼ë§**: Celery â†’ Lambda Auto Scaler (1ë¶„ ë‹¨ìœ„)
âœ… **ë¹„ìš©**: ìœ íœ´ ì‹œ $0, í”¼í¬ ì‹œ $5/hour
âœ… **OOM ë°©ì§€**: ë©”ëª¨ë¦¬ ê´€ë¦¬ + Circuit Breaker

### 12.2 ë¹„ìš© ì ˆê° íš¨ê³¼

| ì‹œë‚˜ë¦¬ì˜¤ | ê¸°ì¡´ (Redis + Celery) | ìƒˆ ë°©ì‹ (SQS + ASG) | ì ˆê°ë¥  |
|---------|----------------------|---------------------|--------|
| **ìœ íœ´ ì‹œê°„** (18h/day) | $500/month | $6/month | **99%** |
| **í”¼í¬ ì‹œê°„** (6h/day) | $500/month | $921/month | -84% |
| **í‰ê· ** (í™œìš©ë¥  20%) | $850/month | $420/month | **51%** |

**ê²°ë¡ **: íŠ¸ë˜í”½ ë³€ë™ì´ í° ê²½ìš° ìƒˆ ë°©ì‹ì´ í›¨ì”¬ ìœ ë¦¬!

### 12.3 ë‹¤ìŒ ë‹¨ê³„

1. âœ… Terraformìœ¼ë¡œ ì¸í”„ë¼ êµ¬ì¶•
2. âœ… FastAPI ì½”ë“œ ìˆ˜ì • (SQS í†µí•©)
3. âœ… GPU Worker AMI ìƒì„±
4. âœ… Lambda Auto Scaler ë°°í¬
5. âœ… ëª¨ë‹ˆí„°ë§ ì„¤ì •
6. âœ… ë¶€í•˜ í…ŒìŠ¤íŠ¸
7. âœ… í”„ë¡œë•ì…˜ ë°°í¬

---

**ì‘ì„± ì™„ë£Œ!** ğŸ‰

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼í•˜ë©´ **ë¹„ìš© íš¨ìœ¨ì **ì´ê³  **ì•ˆì •ì **ì¸ Queue/Worker ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

**ì˜ˆìƒ êµ¬í˜„ ê¸°ê°„**: 4-5ì£¼
**ì˜ˆìƒ ì›” ë¹„ìš©**: $420/month (ë™ì ‘ 100ëª… ê¸°ì¤€)
**ë¹„ìš© ì ˆê°**: 51% (ê¸°ì¡´ ëŒ€ë¹„)

**í–‰ìš´ì„ ë¹•ë‹ˆë‹¤!** ğŸš€
