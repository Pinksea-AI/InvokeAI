# ë‹¨ì¼ í´ëŸ¬ìŠ¤í„° ë¹„ìš© ìµœì í™” êµ¬ì„± ê°€ì´ë“œ

ì´ ê°€ì´ë“œëŠ” **ë‹¨ì¼ EKS í´ëŸ¬ìŠ¤í„° + ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë¶„ë¦¬ + ê³µìœ  RDS** êµ¬ì„±ìœ¼ë¡œ ë¹„ìš©ì„ ìµœì í™”í•˜ë©´ì„œ ê°œë°œê³¼ ìš´ì˜ í™˜ê²½ì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ëª©ì°¨
1. [ì•„í‚¤í…ì²˜ ê°œìš”](#ì•„í‚¤í…ì²˜-ê°œìš”)
2. [ë§¥ë¶ M2 Max ë¡œì»¬ í™˜ê²½](#ë§¥ë¶-m2-max-ë¡œì»¬-í™˜ê²½)
3. [ë‹¨ì¼ í´ëŸ¬ìŠ¤í„° Terraform](#ë‹¨ì¼-í´ëŸ¬ìŠ¤í„°-terraform)
4. [ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë¶„ë¦¬ ì „ëµ](#ë„¤ì„ìŠ¤í˜ì´ìŠ¤-ë¶„ë¦¬-ì „ëµ)
5. [ê³µìœ  RDS êµ¬ì„±](#ê³µìœ -rds-êµ¬ì„±)
6. [ë¹„ìš© ë¶„ì„](#ë¹„ìš©-ë¶„ì„)
7. [ìš´ì˜ ì‹œ ì£¼ì˜ì‚¬í•­](#ìš´ì˜-ì‹œ-ì£¼ì˜ì‚¬í•­)

---

## ì•„í‚¤í…ì²˜ ê°œìš”

### ê¸°ì¡´ ì•„í‚¤í…ì²˜ vs ìµœì í™” ì•„í‚¤í…ì²˜

**ê¸°ì¡´ (ë¹„ìš© ë†’ìŒ)**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dev EKS Cluster                     â”‚
â”‚ - System Nodes: 2x t3.medium        â”‚
â”‚ - GPU Nodes: 0~5x g4dn.xlarge       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dev RDS Aurora (2 instances)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prod EKS Cluster                    â”‚
â”‚ - System Nodes: 3x t3.medium        â”‚
â”‚ - GPU Nodes: 0~10x g4dn.xlarge      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prod RDS Aurora (2 instances)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ì›” ë¹„ìš©: ~$1,800
```

**ìµœì í™” (ë¹„ìš© ì ˆê°)**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Single EKS Cluster                              â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Namespace:   â”‚      â”‚ Namespace:   â”‚       â”‚
â”‚  â”‚    dev       â”‚      â”‚    prod      â”‚       â”‚
â”‚  â”‚              â”‚      â”‚              â”‚       â”‚
â”‚  â”‚ Services     â”‚      â”‚ Services     â”‚       â”‚
â”‚  â”‚ Workers      â”‚      â”‚ Workers      â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                 â”‚
â”‚ System Nodes: 2x t3.medium (ê³µìœ )              â”‚
â”‚ GPU Nodes: Karpenter ìë™ ìŠ¤ì¼€ì¼ë§ (ê³µìœ )      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Shared RDS Aurora (1 writer, 1 reader)         â”‚
â”‚ - DB: pingvas_saas                              â”‚
â”‚   - Schema: dev_pingvas (ê°œë°œ)                 â”‚
â”‚   - Schema: prod_pingvas (ìš´ì˜)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ì›” ë¹„ìš©: ~$680 (62% ì ˆê°)
```

### ì£¼ìš” ì°¨ì´ì 

| í•­ëª© | ê¸°ì¡´ | ìµœì í™” |
|------|------|--------|
| EKS í´ëŸ¬ìŠ¤í„° | 2ê°œ | 1ê°œ |
| Control Plane ë¹„ìš© | $144/ì›” | $72/ì›” |
| System ë…¸ë“œ | 5ê°œ | 2ê°œ |
| RDS ì¸ìŠ¤í„´ìŠ¤ | 4ê°œ | 2ê°œ |
| Redis í´ëŸ¬ìŠ¤í„° | 2ê°œ | 1ê°œ (dev/prod DB ë¶„ë¦¬) |
| NAT Gateway | 6ê°œ | 3ê°œ |
| ë°ì´í„° ì „ì†¡ | ë³„ë„ | ê³µìœ  |

---

## ë§¥ë¶ M2 Max ë¡œì»¬ í™˜ê²½

### 1. Rosetta 2 ì„¤ì • (x86 ì´ë¯¸ì§€ ì§€ì›)

```bash
# Rosetta 2 ì„¤ì¹˜ (ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŒ)
softwareupdate --install-rosetta

# Docker Desktop ì„¤ì •
# Settings > Features in Development > Use Rosetta for x86/amd64 emulation (ì²´í¬)
```

---

### 2. Docker Desktop ë¦¬ì†ŒìŠ¤ í• ë‹¹

ë§¥ë¶ M2 Max 96GB í™˜ê²½ì—ì„œ ê¶Œì¥ ì„¤ì •:

**Docker Desktop > Preferences > Resources**:
```
CPUs: 8 cores (ê°œë°œ í™˜ê²½ìš©)
Memory: 32 GB (ì‹œìŠ¤í…œì— 64GB ë‚¨ê¹€)
Swap: 4 GB
Disk: 100 GB
```

---

### 3. ARM64 ë„¤ì´í‹°ë¸Œ ì´ë¯¸ì§€ ì‚¬ìš©

ë¡œì»¬ ê°œë°œ ì‹œ ARM64 ì´ë¯¸ì§€ ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ:

`docker-compose.dev.yaml` (ARM64 ìµœì í™”):
```yaml
version: '3.8'

services:
  postgres:
    image: postgres:17.4
    platform: linux/arm64  # M2 ë„¤ì´í‹°ë¸Œ
    # ... rest of config

  redis:
    image: redis:7.2-alpine
    platform: linux/arm64
    # ... rest of config

  # LocalStackì€ x86ë§Œ ì§€ì›
  localstack:
    image: localstack/localstack:latest
    platform: linux/amd64  # Rosetta 2ë¡œ ì‹¤í–‰
    # ... rest of config
```

---

### 4. Python ê°œë°œ í™˜ê²½ (ARM64)

```bash
# Python 3.11 ARM64 ë„¤ì´í‹°ë¸Œ ì„¤ì¹˜
brew install python@3.11

# í™•ì¸
python3.11 --version
file $(which python3.11)
# /opt/homebrew/bin/python3.11: Mach-O 64-bit executable arm64

# PyTorch ARM64 (MPS ì§€ì›)
pip3 install torch torchvision torchaudio

# í…ŒìŠ¤íŠ¸
python3 -c "import torch; print(torch.backends.mps.is_available())"
# True (Metal Performance Shaders ì‚¬ìš© ê°€ëŠ¥)
```

---

### 5. ë¡œì»¬ì—ì„œ MPS í™œìš© í…ŒìŠ¤íŠ¸

M2 Maxì˜ GPU (38-core)ë¥¼ í™œìš©í•œ ë¡œì»¬ í…ŒìŠ¤íŠ¸:

`test_local_mps.py`:
```python
import torch
from diffusers import StableDiffusionPipeline
import time

# MPS (Metal Performance Shaders) ë””ë°”ì´ìŠ¤ ì‚¬ìš©
device = "mps" if torch.backends.mps.is_available() else "cpu"
print(f"Using device: {device}")

# ëª¨ë¸ ë¡œë“œ
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
).to(device)

# ì´ë¯¸ì§€ ìƒì„±
start = time.time()
image = pipe(
    "A beautiful sunset over mountains",
    num_inference_steps=30
).images[0]

duration = time.time() - start
print(f"Generation time: {duration:.2f}s")

image.save("output.png")
```

**ì„±ëŠ¥ ë¹„êµ**:
- CPU (M2 Max): ~120ì´ˆ
- MPS (M2 Max GPU): ~15ì´ˆ (8ë°° ë¹ ë¦„)
- AWS g4dn.xlarge (T4): ~8ì´ˆ

---

## ë‹¨ì¼ í´ëŸ¬ìŠ¤í„° Terraform

### 1. ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
infra/terraform/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ vpc/
â”‚   â”œâ”€â”€ eks-single/         # ë‹¨ì¼ í´ëŸ¬ìŠ¤í„° ëª¨ë“ˆ
â”‚   â”œâ”€â”€ rds-shared/         # ê³µìœ  RDS ëª¨ë“ˆ
â”‚   â”œâ”€â”€ elasticache-shared/ # ê³µìœ  Redis ëª¨ë“ˆ
â”‚   â””â”€â”€ s3/
â””â”€â”€ environments/
    â””â”€â”€ shared/             # dev+prod í†µí•© í™˜ê²½
        â”œâ”€â”€ main.tf
        â”œâ”€â”€ variables.tf
        â””â”€â”€ terraform.tfvars
```

---

### 2. ë‹¨ì¼ í´ëŸ¬ìŠ¤í„° ëª¨ë“ˆ

`infra/terraform/modules/eks-single/main.tf`:
```hcl
# EKS Cluster (ë‹¨ì¼)
resource "aws_eks_cluster" "main" {
  name     = var.cluster_name
  role_arn = aws_iam_role.cluster.arn
  version  = var.kubernetes_version

  vpc_config {
    subnet_ids              = concat(var.public_subnet_ids, var.private_subnet_ids)
    endpoint_private_access = true
    endpoint_public_access  = true
  }

  tags = {
    Name        = var.cluster_name
    Environment = "shared"  # dev + prod
  }
}

# System Node Group (ê³µìœ )
resource "aws_eks_node_group" "system" {
  cluster_name    = aws_eks_cluster.main.name
  node_group_name = "${var.cluster_name}-system"
  node_role_arn   = aws_iam_role.node_group.arn
  subnet_ids      = var.private_subnet_ids

  scaling_config {
    desired_size = 2
    max_size     = 4
    min_size     = 2
  }

  instance_types = ["t3.medium"]
  capacity_type  = "SPOT"  # ë¹„ìš© ì ˆê°

  labels = {
    role = "system"
    tier = "shared"
  }

  # Taints ì—†ìŒ (dev/prod ì›Œí¬ë¡œë“œ ëª¨ë‘ í—ˆìš©)

  tags = {
    Name = "${var.cluster_name}-system-shared"
  }
}

# Karpenter Node IAM Role (GPU ë…¸ë“œìš©)
# ... (Phase 4ì™€ ë™ì¼í•˜ì§€ë§Œ sharedë¡œ íƒœê·¸)
```

---

### 3. ê³µìœ  RDS ëª¨ë“ˆ

`infra/terraform/modules/rds-shared/main.tf`:
```hcl
# RDS Aurora Cluster (ë‹¨ì¼, dev+prod ê³µìœ )
resource "aws_rds_cluster" "shared" {
  cluster_identifier      = "pingvas-shared-aurora"
  engine                  = "aurora-postgresql"
  engine_version          = "15.4"
  database_name           = "pingvas_saas"
  master_username         = var.master_username
  master_password         = var.master_password

  # ë¹„ìš© ìµœì í™”: Serverless v2
  engine_mode             = "provisioned"
  serverlessv2_scaling_configuration {
    max_capacity = 4.0  # ìµœëŒ€ 4 ACU
    min_capacity = 0.5  # ìµœì†Œ 0.5 ACU (ê°œë°œ ì‹œê°„ ì™¸ ì ˆê°)
  }

  db_subnet_group_name    = aws_db_subnet_group.main.name
  vpc_security_group_ids  = [aws_security_group.rds.id]

  backup_retention_period = 7
  preferred_backup_window = "03:00-04:00"

  enabled_cloudwatch_logs_exports = ["postgresql"]
  storage_encrypted               = true

  # ìš´ì˜ ì¤‘ì—ëŠ” deletion_protection = true
  deletion_protection = false
  skip_final_snapshot = false
  final_snapshot_identifier = "pingvas-shared-final-snapshot-${formatdate("YYYY-MM-DD-hhmm", timestamp())}"

  tags = {
    Name        = "pingvas-shared-aurora"
    Environment = "shared"
    Purpose     = "dev-and-prod"
  }
}

# Writer Instance (Serverless v2)
resource "aws_rds_cluster_instance" "writer" {
  identifier         = "pingvas-shared-writer"
  cluster_identifier = aws_rds_cluster.shared.id
  instance_class     = "db.serverless"
  engine             = aws_rds_cluster.shared.engine
  engine_version     = aws_rds_cluster.shared.engine_version

  performance_insights_enabled = true

  tags = {
    Name = "pingvas-shared-writer"
    Role = "writer"
  }
}

# Reader Instance (Serverless v2)
resource "aws_rds_cluster_instance" "reader" {
  identifier         = "pingvas-shared-reader"
  cluster_identifier = aws_rds_cluster.shared.id
  instance_class     = "db.serverless"
  engine             = aws_rds_cluster.shared.engine
  engine_version     = aws_rds_cluster.shared.engine_version

  performance_insights_enabled = true

  tags = {
    Name = "pingvas-shared-reader"
    Role = "reader"
  }
}
```

---

### 4. ê³µìœ  í™˜ê²½ Main

`infra/terraform/environments/shared/main.tf`:
```hcl
terraform {
  required_version = ">= 1.6"

  backend "s3" {
    bucket = "pingvas-terraform-state"
    key    = "shared/terraform.tfstate"  # ë‹¨ì¼ state íŒŒì¼
    region = "us-east-1"
  }
}

provider "aws" {
  region = "us-east-1"
}

locals {
  cluster_name = "pingvas-shared-eks"
  vpc_cidr     = "10.0.0.0/16"
}

# VPC
module "vpc" {
  source = "../../modules/vpc"

  environment        = "shared"
  vpc_cidr           = local.vpc_cidr
  cluster_name       = local.cluster_name
  enable_nat_gateway = true

  # ë¹„ìš© ì ˆê°: NAT Gateway 1ê°œë§Œ (ê³ ê°€ìš©ì„± í•„ìš”ì‹œ 3ê°œ)
  single_nat_gateway = true
}

# EKS (ë‹¨ì¼ í´ëŸ¬ìŠ¤í„°)
module "eks" {
  source = "../../modules/eks-single"

  cluster_name       = local.cluster_name
  kubernetes_version = "1.28"
  public_subnet_ids  = module.vpc.public_subnet_ids
  private_subnet_ids = module.vpc.private_subnet_ids
}

# RDS (ê³µìœ )
module "rds" {
  source = "../../modules/rds-shared"

  vpc_id              = module.vpc.vpc_id
  private_subnet_ids  = module.vpc.private_subnet_ids
  allowed_cidr_blocks = [local.vpc_cidr]

  master_username = "pingvas_admin"
  master_password = var.db_password  # Secrets Managerì—ì„œ ê°€ì ¸ì˜¤ê¸°
}

# ElastiCache (ê³µìœ , DB ë²ˆí˜¸ë¡œ ë¶„ë¦¬)
module "elasticache" {
  source = "../../modules/elasticache-shared"

  vpc_id              = module.vpc.vpc_id
  private_subnet_ids  = module.vpc.private_subnet_ids
  allowed_cidr_blocks = [local.vpc_cidr]

  # ë‹¨ì¼ Redis í´ëŸ¬ìŠ¤í„° (DB 0: dev, DB 1: prod)
  num_cache_nodes = 2  # ê³ ê°€ìš©ì„±
  node_type       = "cache.r6g.large"
}

# S3 (í™˜ê²½ë³„ ë²„í‚·)
module "s3" {
  source = "../../modules/s3"

  buckets = {
    dev_images  = "pingvas-dev-images"
    prod_images = "pingvas-prod-images"
    models      = "pingvas-models-shared"  # ëª¨ë¸ì€ ê³µìœ 
    logs        = "pingvas-logs-shared"
  }
}

# EFS (ê³µìœ  ëª¨ë¸ ì €ì¥ì†Œ)
module "efs" {
  source = "../../modules/efs"

  vpc_id              = module.vpc.vpc_id
  private_subnet_ids  = module.vpc.private_subnet_ids
  allowed_cidr_blocks = [local.vpc_cidr]

  tags = {
    Name = "pingvas-models-shared-efs"
  }
}
```

`infra/terraform/environments/shared/terraform.tfvars`:
```hcl
# DB ë¹„ë°€ë²ˆí˜¸ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •
# export TF_VAR_db_password="your_secure_password"
```

---

## ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë¶„ë¦¬ ì „ëµ

### 1. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±

`k8s/namespaces/namespaces.yaml`:
```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: dev
  labels:
    environment: dev
    istio-injection: enabled  # Service Mesh ì‚¬ìš© ì‹œ
---
apiVersion: v1
kind: Namespace
metadata:
  name: prod
  labels:
    environment: prod
    istio-injection: enabled
```

---

### 2. ResourceQuota (ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë³„ ë¦¬ì†ŒìŠ¤ ì œí•œ)

`k8s/namespaces/dev-quota.yaml`:
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: dev-quota
  namespace: dev
spec:
  hard:
    requests.cpu: "20"        # ìµœëŒ€ 20 CPU
    requests.memory: 50Gi     # ìµœëŒ€ 50GB ë©”ëª¨ë¦¬
    requests.nvidia.com/gpu: "3"  # ìµœëŒ€ 3 GPU
    pods: "50"                # ìµœëŒ€ 50 pods
    services: "20"
    persistentvolumeclaims: "10"
```

`k8s/namespaces/prod-quota.yaml`:
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: prod-quota
  namespace: prod
spec:
  hard:
    requests.cpu: "50"        # ìµœëŒ€ 50 CPU
    requests.memory: 200Gi    # ìµœëŒ€ 200GB ë©”ëª¨ë¦¬
    requests.nvidia.com/gpu: "15"  # ìµœëŒ€ 15 GPU
    pods: "200"
    services: "50"
    persistentvolumeclaims: "30"
```

---

### 3. NetworkPolicy (ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê°„ ê²©ë¦¬)

`k8s/network-policies/deny-cross-namespace.yaml`:
```yaml
# Dev ë„¤ì„ìŠ¤í˜ì´ìŠ¤: Prodë¡œì˜ íŠ¸ë˜í”½ ì°¨ë‹¨
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-to-prod
  namespace: dev
spec:
  podSelector: {}
  policyTypes:
    - Egress
  egress:
    # ê°™ì€ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í—ˆìš©
    - to:
      - namespaceSelector:
          matchLabels:
            environment: dev

    # ì™¸ë¶€ ì¸í„°ë„· í—ˆìš© (DNS, AWS APIs ë“±)
    - to:
      - namespaceSelector: {}
      ports:
        - protocol: TCP
          port: 443
        - protocol: UDP
          port: 53

    # RDS/Redis ì ‘ê·¼ í—ˆìš© (VPC CIDR)
    - to:
      - ipBlock:
          cidr: 10.0.0.0/16

---
# Prod ë„¤ì„ìŠ¤í˜ì´ìŠ¤: Devë¡œì˜ íŠ¸ë˜í”½ ì°¨ë‹¨
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-to-dev
  namespace: prod
spec:
  podSelector: {}
  policyTypes:
    - Egress
  egress:
    - to:
      - namespaceSelector:
          matchLabels:
            environment: prod
    - to:
      - namespaceSelector: {}
      ports:
        - protocol: TCP
          port: 443
        - protocol: UDP
          port: 53
    - to:
      - ipBlock:
          cidr: 10.0.0.0/16
```

---

### 4. PriorityClass (Prod ìš°ì„ ìˆœìœ„)

`k8s/priority/priority-classes.yaml`:
```yaml
# Prod ì›Œí¬ë¡œë“œ: ë†’ì€ ìš°ì„ ìˆœìœ„
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: prod-high
value: 1000000
globalDefault: false
description: "High priority for production workloads"

---
# Prod ì‹œìŠ¤í…œ: ë§¤ìš° ë†’ì€ ìš°ì„ ìˆœìœ„
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: prod-critical
value: 2000000
globalDefault: false
description: "Critical priority for production system workloads"

---
# Dev ì›Œí¬ë¡œë“œ: ë‚®ì€ ìš°ì„ ìˆœìœ„
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: dev-low
value: 100000
globalDefault: false
description: "Low priority for development workloads"
```

**Deploymentì— ì ìš©**:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
  namespace: prod
spec:
  template:
    spec:
      priorityClassName: prod-high  # ìš°ì„ ìˆœìœ„ ì§€ì •
      containers:
        - name: user-service
          # ...
```

---

## ê³µìœ  RDS êµ¬ì„±

### 1. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë¶„ë¦¬

```sql
-- ì´ˆê¸° ì„¤ì • (Terraform ì´í›„ ìˆ˜ë™ ì‹¤í–‰ ë˜ëŠ” init container)

-- Dev ìŠ¤í‚¤ë§ˆ
CREATE SCHEMA IF NOT EXISTS dev_pingvas;

-- Prod ìŠ¤í‚¤ë§ˆ
CREATE SCHEMA IF NOT EXISTS prod_pingvas;

-- Dev ì „ìš© ì‚¬ìš©ì (ì„ íƒ)
CREATE USER dev_user WITH PASSWORD 'dev_password';
GRANT ALL PRIVILEGES ON SCHEMA dev_pingvas TO dev_user;
GRANT USAGE ON SCHEMA dev_pingvas TO dev_user;
ALTER DEFAULT PRIVILEGES IN SCHEMA dev_pingvas
  GRANT ALL ON TABLES TO dev_user;

-- Prod ì „ìš© ì‚¬ìš©ì
CREATE USER prod_user WITH PASSWORD 'prod_password';
GRANT ALL PRIVILEGES ON SCHEMA prod_pingvas TO prod_user;
GRANT USAGE ON SCHEMA prod_pingvas TO prod_user;
ALTER DEFAULT PRIVILEGES IN SCHEMA prod_pingvas
  GRANT ALL ON TABLES TO prod_user;

-- ê¸°ë³¸ search_path ì„¤ì •
ALTER USER dev_user SET search_path TO dev_pingvas, public;
ALTER USER prod_user SET search_path TO prod_pingvas, public;
```

---

### 2. K8s Secret (í™˜ê²½ë³„)

`k8s/secrets/dev-db-credentials.yaml`:
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: db-credentials
  namespace: dev
type: Opaque
stringData:
  DATABASE_URL: "postgresql://dev_user:dev_password@pingvas-shared-writer.xxxxx.us-east-1.rds.amazonaws.com:5432/pingvas_saas?options=-c%20search_path=dev_pingvas"
  DB_SCHEMA: "dev_pingvas"
```

`k8s/secrets/prod-db-credentials.yaml`:
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: db-credentials
  namespace: prod
type: Opaque
stringData:
  DATABASE_URL: "postgresql://prod_user:prod_password@pingvas-shared-writer.xxxxx.us-east-1.rds.amazonaws.com:5432/pingvas_saas?options=-c%20search_path=prod_pingvas"
  DB_SCHEMA: "prod_pingvas"
```

---

### 3. Redis DB ë¶„ë¦¬

RedisëŠ” ë‹¨ì¼ í´ëŸ¬ìŠ¤í„°ì´ì§€ë§Œ DB ë²ˆí˜¸ë¡œ ë¶„ë¦¬:

**Dev**: `redis://redis-primary:6379/0`
**Prod**: `redis://redis-primary:6379/1`

`k8s/configmaps/redis-config.yaml`:
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config
  namespace: dev
data:
  REDIS_URL: "redis://redis-primary.default.svc.cluster.local:6379/0"
  REDIS_DB: "0"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config
  namespace: prod
data:
  REDIS_URL: "redis://redis-primary.default.svc.cluster.local:6379/1"
  REDIS_DB: "1"
```

---

### 4. ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜

í™˜ê²½ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜ ê´€ë¦¬:

`db/migrations/run-migration.sh`:
```bash
#!/bin/bash

ENVIRONMENT=$1  # dev or prod

if [ "$ENVIRONMENT" = "dev" ]; then
    export DATABASE_URL="postgresql://dev_user:dev_password@<RDS_ENDPOINT>:5432/pingvas_saas"
    export DB_SCHEMA="dev_pingvas"
elif [ "$ENVIRONMENT" = "prod" ]; then
    export DATABASE_URL="postgresql://prod_user:prod_password@<RDS_ENDPOINT>:5432/pingvas_saas"
    export DB_SCHEMA="prod_pingvas"
else
    echo "Usage: $0 {dev|prod}"
    exit 1
fi

# Alembic migration
cd services/user-service
alembic upgrade head

echo "Migration completed for $ENVIRONMENT"
```

---

## ë¹„ìš© ë¶„ì„

### ì›”ë³„ ë¹„ìš© ë¹„êµ

#### ê¸°ì¡´ ì•„í‚¤í…ì²˜ (ë³„ë„ í´ëŸ¬ìŠ¤í„°)

| í•­ëª© | ìˆ˜ëŸ‰ | ë‹¨ê°€ | ì›” ë¹„ìš© |
|------|------|------|---------|
| **EKS Control Plane** | 2 | $72 | $144 |
| **System Nodes (t3.medium)** | 5 | $30.40 | $152 |
| **RDS Aurora (db.r6g.large)** | 4 | $208 | $832 |
| **ElastiCache (cache.r6g.large)** | 4 | $154 | $616 |
| **NAT Gateway** | 6 | $32.40 | $194.40 |
| **GPU Nodes (í‰ê· )** | | | $200 |
| **ë°ì´í„° ì „ì†¡** | | | $100 |
| **S3 + CloudFront** | | | $80 |
| **ì´ê³„** | | | **$2,318.40** |

---

#### ìµœì í™” ì•„í‚¤í…ì²˜ (ë‹¨ì¼ í´ëŸ¬ìŠ¤í„°)

| í•­ëª© | ìˆ˜ëŸ‰ | ë‹¨ê°€ | ì›” ë¹„ìš© | ì ˆê° |
|------|------|------|---------|------|
| **EKS Control Plane** | 1 | $72 | $72 | -$72 |
| **System Nodes (t3.medium Spot)** | 2 | $9.12 | $18.24 | -$133.76 |
| **RDS Aurora Serverless v2** | 2 | $87 | $174 | -$658 |
| **ElastiCache (cache.r6g.large)** | 2 | $154 | $308 | -$308 |
| **NAT Gateway** | 1 | $32.40 | $32.40 | -$162 |
| **GPU Nodes (í‰ê· )** | | | $200 | $0 |
| **ë°ì´í„° ì „ì†¡** | | | $60 | -$40 |
| **S3 + CloudFront** | | | $80 | $0 |
| **ì´ê³„** | | | **$944.64** | **-$1,373.76** |

**ì ˆê°ìœ¨: 59.2%**

---

### ë¹„ìš© ì ˆê° ì „ëµ

1. **Aurora Serverless v2**
   - ê°œë°œ ì‹œê°„ ì™¸ ìë™ Scale-to-Zero (0.5 ACU)
   - ìš´ì˜ ì¤‘ì—ë§Œ ìŠ¤ì¼€ì¼ ì—… (ìµœëŒ€ 4 ACU)
   - ê³ ì • ì¸ìŠ¤í„´ìŠ¤ ëŒ€ë¹„ 70% ì ˆê°

2. **Spot Instances**
   - System ë…¸ë“œ: Spotìœ¼ë¡œ 70% ì ˆê°
   - GPU ë…¸ë“œ: ì´ë¯¸ Spot ì‚¬ìš©

3. **ë‹¨ì¼ NAT Gateway**
   - ê°œë°œ í™˜ê²½ì—ì„œëŠ” ê³ ê°€ìš©ì„±ë³´ë‹¤ ë¹„ìš© ìš°ì„ 
   - ìš´ì˜ ì•ˆì •í™” í›„ 3ê°œë¡œ í™•ì¥ ê³ ë ¤

4. **ê³µìœ  ë¦¬ì†ŒìŠ¤**
   - EFS: ë‹¨ì¼ íŒŒì¼ì‹œìŠ¤í…œ (ëª¨ë¸ ê³µìœ )
   - S3: ì´ë¯¸ì§€ëŠ” ë¶„ë¦¬, ëª¨ë¸ì€ ê³µìœ 

---

## ìš´ì˜ ì‹œ ì£¼ì˜ì‚¬í•­

### 1. ë¦¬ì†ŒìŠ¤ ê²½í•© ë°©ì§€

**ResourceQuota ëª¨ë‹ˆí„°ë§**:
```bash
# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë³„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
kubectl describe quota -n dev
kubectl describe quota -n prod

# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
watch kubectl top nodes
watch kubectl top pods -n prod
```

**ì•ŒëŒ ì„¤ì •**:
```yaml
# Prometheus Alert
- alert: DevResourceQuotaExceeded
  expr: kube_resourcequota{namespace="dev",type="used"} / kube_resourcequota{namespace="dev",type="hard"} > 0.9
  for: 5m
  annotations:
    summary: "Dev namespace is using >90% of quota"
```

---

### 2. ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼ ì œì–´

**ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ê²€ì¦**:
```python
# services/user-service/app/db/base.py

from sqlalchemy import event, create_engine

engine = create_engine(settings.database_url)

@event.listens_for(engine, "connect")
def enforce_schema(dbapi_conn, connection_record):
    """
    ì—°ê²° ì‹œ ìŠ¤í‚¤ë§ˆ ê°•ì œ
    """
    cursor = dbapi_conn.cursor()

    # í™˜ê²½ì— ë§ëŠ” ìŠ¤í‚¤ë§ˆë§Œ ì ‘ê·¼ ê°€ëŠ¥
    if settings.environment == "dev":
        cursor.execute("SET search_path TO dev_pingvas, public")
    elif settings.environment == "prod":
        cursor.execute("SET search_path TO prod_pingvas, public")
    else:
        raise ValueError(f"Invalid environment: {settings.environment}")

    cursor.close()
```

**RDS Parameter Group**:
```hcl
resource "aws_db_parameter_group" "main" {
  name   = "pingvas-shared-params"
  family = "aurora-postgresql15"

  parameter {
    name  = "log_statement"
    value = "ddl"  # DDL ì¿¼ë¦¬ ë¡œê¹… (ìŠ¤í‚¤ë§ˆ ë³€ê²½ ê°ì§€)
  }

  parameter {
    name  = "log_connections"
    value = "1"  # ì—°ê²° ë¡œê¹…
  }
}
```

---

### 3. ë°°í¬ ìˆœì„œ (Prod ì˜í–¥ ìµœì†Œí™”)

**ArgoCD ApplicationSet ìš°ì„ ìˆœìœ„**:
```yaml
apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata:
  name: pingvas-services
spec:
  generators:
    - list:
        elements:
          # Dev ë¨¼ì € ë°°í¬
          - env: dev
            namespace: dev
            syncWave: "1"

          # ProdëŠ” ë‚˜ì¤‘ì— ë°°í¬ (ìˆ˜ë™ ìŠ¹ì¸)
          - env: prod
            namespace: prod
            syncWave: "2"

  template:
    spec:
      syncPolicy:
        automated:
          prune: true
          selfHeal: '{{ if eq .env "dev" }}true{{ else }}false{{ end }}'

        # ProdëŠ” ìˆ˜ë™ ìŠ¹ì¸ í•„ìš”
        syncOptions:
          - CreateNamespace=true
```

**GitHub Actions (ìŠ¹ì¸ ë‹¨ê³„)**:
```yaml
# .github/workflows/cd-prod.yaml

jobs:
  deploy-prod:
    runs-on: ubuntu-latest
    environment: production  # Requires approval

    steps:
      - name: Wait for approval
        uses: trstringer/manual-approval@v1
        with:
          secret: ${{ secrets.GITHUB_TOKEN }}
          approvers: user1,user2
          minimum-approvals: 1
          issue-title: "Deploying v${{ github.ref_name }} to production"
```

---

### 4. ëª¨ë‹ˆí„°ë§ ë¶„ë¦¬

**Grafana ëŒ€ì‹œë³´ë“œ ë¶„ë¦¬**:
```json
{
  "dashboard": {
    "title": "Production Metrics",
    "panels": [
      {
        "title": "Prod Namespace CPU",
        "targets": [{
          "expr": "sum(rate(container_cpu_usage_seconds_total{namespace=\"prod\"}[5m]))"
        }]
      }
    ]
  }
}
```

**AlertManager ë¼ìš°íŒ…**:
```yaml
# alertmanager-config.yaml
route:
  routes:
    # Prod ì•ŒëŒ: ì¦‰ì‹œ ë°œì†¡
    - match:
        namespace: prod
      receiver: pagerduty-prod
      group_wait: 10s
      repeat_interval: 5m

    # Dev ì•ŒëŒ: Slackë§Œ
    - match:
        namespace: dev
      receiver: slack-dev
      group_wait: 5m
      repeat_interval: 1h
```

---

### 5. ë°±ì—… ì „ëµ

**Prod ìŠ¤í‚¤ë§ˆë§Œ ì •ê¸° ë°±ì—…**:
```bash
# backup-prod-schema.sh

#!/bin/bash

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="prod_backup_${TIMESTAMP}.sql"

# Prod ìŠ¤í‚¤ë§ˆë§Œ ë¤í”„
pg_dump \
  -h pingvas-shared-writer.xxxxx.rds.amazonaws.com \
  -U prod_user \
  -d pingvas_saas \
  -n prod_pingvas \
  --format=custom \
  --file=/backups/${BACKUP_FILE}

# S3 ì—…ë¡œë“œ
aws s3 cp /backups/${BACKUP_FILE} s3://pingvas-backups/prod/

# ë¡œì»¬ íŒŒì¼ ì‚­ì œ (7ì¼ ì´ìƒ)
find /backups -name "prod_backup_*.sql" -mtime +7 -delete

echo "Backup completed: ${BACKUP_FILE}"
```

**CronJobìœ¼ë¡œ ìë™í™”**:
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: prod-db-backup
  namespace: prod
spec:
  schedule: "0 2 * * *"  # ë§¤ì¼ ì˜¤ì „ 2ì‹œ
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: backup
              image: postgres:15
              command: ["/scripts/backup-prod-schema.sh"]
              volumeMounts:
                - name: backup-script
                  mountPath: /scripts
          restartPolicy: OnFailure
```

---

### 6. ì¥ì•  ê²©ë¦¬

**Circuit Breaker íŒ¨í„´**:
```python
# services/generation-service/app/utils/circuit_breaker.py

from circuitbreaker import circuit

@circuit(failure_threshold=5, recovery_timeout=60)
def call_payment_service(user_id: str):
    """
    Payment Service í˜¸ì¶œ (ì‹¤íŒ¨ ì‹œ Circuit Open)
    """
    response = httpx.get(
        f"http://payment-service.{NAMESPACE}.svc.cluster.local:8002/api/v1/credits/balance/{user_id}",
        timeout=5.0
    )
    return response.json()
```

---

## ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë¡œì»¬ í™˜ê²½
- [ ] ë§¥ë¶ M2 Max Docker Desktop ì„¤ì • (32GB ë©”ëª¨ë¦¬)
- [ ] Rosetta 2 í™œì„±í™”
- [ ] ARM64 ë„¤ì´í‹°ë¸Œ ì´ë¯¸ì§€ ì‚¬ìš©
- [ ] MPS GPU í…ŒìŠ¤íŠ¸ ì„±ê³µ

### AWS ì¸í”„ë¼
- [ ] ë‹¨ì¼ EKS í´ëŸ¬ìŠ¤í„° ìƒì„±
- [ ] Spot ì¸ìŠ¤í„´ìŠ¤ë¡œ System ë…¸ë“œ êµ¬ì„±
- [ ] Aurora Serverless v2 êµ¬ì„±
- [ ] ìŠ¤í‚¤ë§ˆ ë¶„ë¦¬ (dev_pingvas, prod_pingvas)
- [ ] ë‹¨ì¼ Redis í´ëŸ¬ìŠ¤í„° (DB 0, 1 ë¶„ë¦¬)

### Kubernetes ì„¤ì •
- [ ] ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± (dev, prod)
- [ ] ResourceQuota ì ìš©
- [ ] NetworkPolicy ì ìš©
- [ ] PriorityClass ì„¤ì •
- [ ] í™˜ê²½ë³„ Secret/ConfigMap ìƒì„±

### ìš´ì˜
- [ ] ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
- [ ] Prod ì•ŒëŒ ì„¤ì •
- [ ] ë°±ì—… ìë™í™”
- [ ] ë°°í¬ ìŠ¹ì¸ í”„ë¡œì„¸ìŠ¤

---

## ë‹¤ìŒ ë‹¨ê³„

ë‹¨ì¼ í´ëŸ¬ìŠ¤í„° êµ¬ì„±ì´ ì™„ë£Œë˜ë©´:

1. **Phase 1 ìˆ˜ì •íŒ**: M2 Max ìµœì í™” ë¡œì»¬ í™˜ê²½
2. **Phase 3 ìˆ˜ì •íŒ**: ë‹¨ì¼ í´ëŸ¬ìŠ¤í„° Terraform ì ìš©
3. **Phase 5 ìˆ˜ì •íŒ**: ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê¸°ë°˜ ArgoCD ì„¤ì •

**ğŸ‘‰ ë‹¤ìŒ ë¬¸ì„œ: [ê¸°ì¡´ ê°€ì´ë“œ ìˆ˜ì • ì‚¬í•­](./migration-updates-required.md)**
